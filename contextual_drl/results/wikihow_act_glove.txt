
 Arguments:
action_rate: 0.1
agent_mode: act
batch_size: 32
context_len: 100
contextual_embedding: glove
dense_dim: 256
dis_dim: 100
display_training_result: 1
domain: wikihow
dropout: 0.5
epochs: 10
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
filter_act_ind: 1
gamma: 0.9
gui_mode: False
learning_rate: 0.001
load_replay: 0
load_weights: False
model_dim: 50
num_actions: 2
num_filters: 32
num_words: 500
object_rate: 0.07
optimizer: adam
positive_rate: 0.9
priority: 1
random_play: 0
replay_size: 50000
result_dir: results/wikihow_act_glove
reward_assign: [1, 2, 3]
reward_base: 50.0
save_replay: 0
save_replay_name: data/saved_replay_memory.pkl
save_replay_size: 1000
save_weights: True
stacked_embeddings: StackedEmbeddings [/home/nfs/smiglani/.flair/embeddings/glove.gensim]
start_epoch: 0
stop_epoch_gap: 5
tag_dim: 100
target_steps: 5
test_steps: 15000
train_episodes: 50
train_frequency: 1
train_repeat: 1
train_steps: 48000
use_act_rate: 1
valid_steps: 12000
word2vec: <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f920f5b9208>
word_dim: 100



Summary:
total_ecs: 36	 right_ecs: 18	 tagged_ecs: 25
total_act: 688	 right_act: 412	 tagged_act: 588
acc: 0.950896	 rec: 0.598837	 pre: 0.700680	 f1: 0.645768

cumulative reward: 476133.354000	 average reward: 46.388674


 Best f1 value: {'rec': [0.0, 0.5988372093023255], 'pre': [0.0, 0.7006802721088435], 'f1': [0.0, 0.64576802507837], 'rw': [0.0, 46.38867439594712]}  best epoch: 0


Summary:
total_ecs: 36	 right_ecs: 13	 tagged_ecs: 22
total_act: 685	 right_act: 381	 tagged_act: 536
acc: 0.949727	 rec: 0.556204	 pre: 0.710821	 f1: 0.624079

cumulative reward: 471807.990000	 average reward: 45.967263


Summary:
total_ecs: 36	 right_ecs: 11	 tagged_ecs: 18
total_act: 671	 right_act: 317	 tagged_act: 443
acc: 0.945928	 rec: 0.472429	 pre: 0.715576	 f1: 0.569120

cumulative reward: 463053.332000	 average reward: 45.114315


Summary:
total_ecs: 36	 right_ecs: 13	 tagged_ecs: 25
total_act: 688	 right_act: 393	 tagged_act: 626
acc: 0.943687	 rec: 0.571221	 pre: 0.627796	 f1: 0.598174

cumulative reward: 467475.690000	 average reward: 45.545176


Summary:
total_ecs: 36	 right_ecs: 12	 tagged_ecs: 18
total_act: 676	 right_act: 318	 tagged_act: 478
acc: 0.942810	 rec: 0.470414	 pre: 0.665272	 f1: 0.551127

cumulative reward: 459839.004000	 average reward: 44.801150


Summary:
total_ecs: 36	 right_ecs: 10	 tagged_ecs: 18
total_act: 682	 right_act: 339	 tagged_act: 538
acc: 0.941056	 rec: 0.497067	 pre: 0.630112	 f1: 0.555738

cumulative reward: 458810.746000	 average reward: 44.700969


Summary:
total_ecs: 36	 right_ecs: 10	 tagged_ecs: 14
total_act: 674	 right_act: 313	 tagged_act: 451
acc: 0.943979	 rec: 0.464392	 pre: 0.694013	 f1: 0.556444

cumulative reward: 460032.988000	 average reward: 44.820049


Summary:
total_ecs: 36	 right_ecs: 10	 tagged_ecs: 18
total_act: 680	 right_act: 318	 tagged_act: 484
acc: 0.942225	 rec: 0.467647	 pre: 0.657025	 f1: 0.546392

cumulative reward: 458012.683000	 average reward: 44.623215


Summary:
total_ecs: 36	 right_ecs: 11	 tagged_ecs: 19
total_act: 677	 right_act: 340	 tagged_act: 538
acc: 0.941251	 rec: 0.502216	 pre: 0.631970	 f1: 0.559671

cumulative reward: 460378.083000	 average reward: 44.853671


Summary:
total_ecs: 36	 right_ecs: 11	 tagged_ecs: 21
total_act: 681	 right_act: 359	 tagged_act: 599
acc: 0.939302	 rec: 0.527166	 pre: 0.599332	 f1: 0.560937

cumulative reward: 459858.810000	 average reward: 44.803080


Summary:
total_ecs: 36	 right_ecs: 14	 tagged_ecs: 22
total_act: 675	 right_act: 316	 tagged_act: 470
acc: 0.943492	 rec: 0.468148	 pre: 0.672340	 f1: 0.551965

cumulative reward: 460267.006000	 average reward: 44.842849


Summary:
total_ecs: 36	 right_ecs: 12	 tagged_ecs: 20
total_act: 681	 right_act: 361	 tagged_act: 540
acc: 0.945343	 rec: 0.530103	 pre: 0.668519	 f1: 0.591319

cumulative reward: 466201.460000	 average reward: 45.421031


Best f1 value: {'rec': [0.0, 0.5988372093023255], 'pre': [0.0, 0.7006802721088435], 'f1': [0.0, 0.64576802507837], 'rw': [0.0, 46.38867439594712]}  best epoch: 0


 training process:
{'rec': [0.0, 0.5988372093023255], 'pre': [0.0, 0.7006802721088435], 'f1': [0.0, 0.64576802507837], 'rw': [0.0, 46.38867439594712]}

rec: [0.5988372093023255]
pre: [0.7006802721088435]
f1: [0.64576802507837]
rw: [46.38867439594712]

Avg f1: 0.64576802507837  Avg reward: 46.38867439594712
