{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give instructions of your domain in natural language. It could be a transcript, domain process manual or wikihow style instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste your input as unicode text here.\n",
    "\n",
    "instructions = u'''Jeff, Barbara and Nirmal are allergic to gluten. Shivam, and Kanav are non-allergic children.\n",
    "\n",
    "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
    "Put gluten-free sandwich on a tray.\n",
    "Move the tray from the kitchen to table5.\n",
    "Serve the gluten-free sandwich to Jeff.\n",
    "Move the tray back from table5 to the kitchen.\n",
    "\n",
    "Make a sandwich with cheese and wheat bread\n",
    "Put sandwich on a tray.\n",
    "Move the tray from kitchen to the table1\n",
    "Serve the sandwich to Shivam.\n",
    "Move the tray back from table1 to the kitchen.\n",
    "\n",
    "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
    "Put gluten-free sandwich on a tray.\n",
    "Move the tray from the kitchen to the table5.\n",
    "Serve the gluten-free sandwich to Jeff.\n",
    "Move the tray back from table5 to the kitchen.\n",
    "\n",
    "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
    "Put gluten-free sandwich on a tray.\n",
    "Make a sandwich with cheese and wheat bread\n",
    "Put sandwich on tray7.\n",
    "\n",
    "Move the tray from the kitchen to the table-5.\n",
    "Serve the gluten-free sandwich to Nirmal.\n",
    "Move the tray back from table5 to the kitchen.\n",
    "\n",
    "Move the tray7 from kitchen to the table1\n",
    "Serve the sandwich to Kanav.\n",
    "Move the tray7 back from table1 to the kitchen.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff, Barbara and Nirmal are allergic to gluten. Shivam, and Kanav are non-allergic children.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move the tray from the kitchen to table5.\n",
      "Serve the gluten-free sandwich to Jeff.\n",
      "Move the tray back from table5 to the kitchen.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on a tray.\n",
      "Move the tray from kitchen to the table1\n",
      "Serve the sandwich to Shivam.\n",
      "Move the tray back from table1 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move the tray from the kitchen to the table5.\n",
      "Serve the gluten-free sandwich to Jeff.\n",
      "Move the tray back from table5 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on tray7.\n",
      "Move the tray from the kitchen to the table-5.\n",
      "Serve the gluten-free sandwich to Nirmal.\n",
      "Move the tray back from table5 to the kitchen.\n",
      "Move the tray7 from kitchen to the table1\n",
      "Serve the sandwich to Kanav.\n",
      "Move the tray7 back from table1 to the kitchen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove empty lines from input instructions -- this is important for BERT which looks at previous and forward sentences.\n",
    "valid_instructions = ''\n",
    "lines = instructions.split(\"\\n\")\n",
    "non_empty_lines = [line for line in lines if line.strip() != \"\"]\n",
    "for line in non_empty_lines:\n",
    "      valid_instructions += line + u\"\\n\"\n",
    "print(valid_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove pronoun coreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff, Barbara and Nirmal are allergic to gluten. Shivam, and Kanav are non-allergic children.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move a tray from the kitchen to table5.\n",
      "Serve gluten-free sandwich to Jeff.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on a tray.\n",
      "Move a tray from kitchen to the table1\n",
      "Serve gluten-free sandwich to Shivam.\n",
      "Move a tray back from table1 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move a tray the kitchen to the table5.\n",
      "Serve gluten-free sandwich to Jeff.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on tray7.\n",
      "Move a tray from the kitchen to the table-5.\n",
      "Serve gluten-free sandwich to Nirmal.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Move tray7 from kitchen to the table1\n",
      "Serve gluten-free sandwich to Kanav.\n",
      "Move tray7 back from table1 to the kitchen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "doc1 = nlp(valid_instructions)\n",
    "coref_resolved_instructions =  doc1._.coref_resolved\n",
    "\n",
    "print(coref_resolved_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write the file into proper directory to be run by main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'childsnack_domain.txt'\n",
    "main_file_name = 'main_ceasdrl.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace input filename in the main file\n",
    "import re\n",
    "\n",
    "# Read in the file\n",
    "with open(main_file_name, 'r') as file :\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = re.sub(r'input_filename = .*txt', \"input_filename = '\"+ fname, filedata)\n",
    "\n",
    "# Write the file out again\n",
    "with open(main_file_name, 'w') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeff, Barbara and Nirmal are allergic to gluten. Shivam, and Kanav are non-allergic children.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move a tray from the kitchen to table5.\n",
      "Serve gluten-free sandwich to Jeff.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on a tray.\n",
      "Move a tray from kitchen to the table1\n",
      "Serve gluten-free sandwich to Shivam.\n",
      "Move a tray back from table1 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move a tray the kitchen to the table5.\n",
      "Serve gluten-free sandwich to Jeff.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on tray7.\n",
      "Move a tray from the kitchen to the table-5.\n",
      "Serve gluten-free sandwich to Nirmal.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Move tray7 from kitchen to the table1\n",
      "Serve gluten-free sandwich to Kanav.\n",
      "Move tray7 back from table1 to the kitchen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Writing the instructions file into directory\n",
    "# Writing the file\n",
    "text_file = open(\"./data/process_manuals/\" + fname, \"w\")\n",
    "text_file.write(coref_resolved_instructions)\n",
    "text_file.close()\n",
    "\n",
    "# Reading the file\n",
    "text_file = open(\"./data/process_manuals/\" + fname, \"r\")\n",
    "print(text_file.read())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract action sequence by running c-EASDRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From main_ceasdrl.py:3: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From main_ceasdrl.py:115: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-07-30 13:09:56.112387: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Initializing the Environment...\n",
      "Initializing the DQN...\n",
      "WARNING:tensorflow:From /Users/shivam/.virtualenvs/contextual_drl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500, 6344, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 499, 1, 32)   406048      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 498, 1, 32)   609056      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 497, 1, 32)   812064      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 496, 1, 32)   1015072     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 499, 1, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 498, 1, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 497, 1, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 496, 1, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 4, 32)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          33024       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            514         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,875,778\n",
      "Trainable params: 2,875,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Initializing the Environment...\n",
      "Initializing the DQN...\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100, 2604, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 99, 1, 32)    166688      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 98, 1, 32)    250016      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 97, 1, 32)    333344      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 1, 32)    416672      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 99, 1, 32)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 98, 1, 32)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 97, 1, 32)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 1, 32)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 4, 32)     0           max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          33024       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            514         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,200,258\n",
      "Trainable params: 1,200,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Loading weights ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from weights/cooking_act_bert.h5 ...\n",
      "Loaded weights from weights/cooking_arg_elmo.h5 ...\n",
      "weights loaded ...\n",
      "Jeff, Barbara and Nirmal are allergic to gluten. Shivam, and Kanav are non-allergic children.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move a tray from the kitchen to table5.\n",
      "Serve gluten-free sandwich to Jeff.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on a tray.\n",
      "Move a tray from kitchen to the table1\n",
      "Serve gluten-free sandwich to Shivam.\n",
      "Move a tray back from table1 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Move a tray the kitchen to the table5.\n",
      "Serve gluten-free sandwich to Jeff.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Make a gluten-free sandwich with gluten-free cheese and corn bread.\n",
      "Put gluten-free sandwich on a tray.\n",
      "Make a sandwich with cheese and wheat bread\n",
      "Put sandwich on tray7.\n",
      "Move a tray from the kitchen to the table-5.\n",
      "Serve gluten-free sandwich to Nirmal.\n",
      "Move a tray back from table5 to the kitchen.\n",
      "Move tray7 from kitchen to the table1\n",
      "Serve gluten-free sandwich to Kanav.\n",
      "Move tray7 back from table1 to the kitchen.\n",
      " \n",
      "100%|███████████████████████████████████████████| 27/27 [00:12<00:00,  2.23it/s]\n",
      "WARNING:tensorflow:From /Users/shivam/.virtualenvs/contextual_drl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "\n",
      "NO1: Jeff(1) Barbara(2) and(3) Nirmal(4) are(5) allergic(6) to(7) gluten(8) \n",
      "\n",
      "NO2: Shivam(1) and(2) Kanav(3) are(4) non-allergic(5) children.(6) \n",
      "\n",
      "NO3: Make(1) a(2) gluten-free(3) sandwich(4) with(5) gluten-free(6) cheese(7) and(8) corn(9) bread.(10) \n",
      "<1>  Make (sandwich, cheese, corn)    \n",
      "\n",
      "NO4: Put(1) gluten-free(2) sandwich(3) on(4) a(5) tray.(6) \n",
      "<2>  Put (sandwich)    \n",
      "\n",
      "NO5: Move(1) a(2) tray(3) from(4) the(5) kitchen(6) to(7) table5.(8) \n",
      "<3>  Move (tray)    \n",
      "\n",
      "NO6: Serve(1) gluten-free(2) sandwich(3) to(4) Jeff.(5) \n",
      "<4>  Serve (sandwich)    \n",
      "\n",
      "NO7: Move(1) a(2) tray(3) back(4) from(5) table5(6) to(7) the(8) kitchen.(9) \n",
      "<5>  Move (tray)    \n",
      "\n",
      "NO8: Make(1) a(2) sandwich(3) with(4) cheese(5) and(6) wheat(7) bread(8) \n",
      "<6>  Make (sandwich, cheese)    \n",
      "\n",
      "NO9: Put(1) sandwich(2) on(3) a(4) tray.(5) \n",
      "<7>  Put (sandwich)    \n",
      "\n",
      "NO10: Move(1) a(2) tray(3) from(4) kitchen(5) to(6) the(7) table1(8) \n",
      "<8>  Move (tray)    \n",
      "\n",
      "NO11: Serve(1) gluten-free(2) sandwich(3) to(4) Shivam.(5) \n",
      "<9>  Serve (sandwich)    \n",
      "\n",
      "NO12: Move(1) a(2) tray(3) back(4) from(5) table1(6) to(7) the(8) kitchen.(9) \n",
      "<10>  Move (tray)    \n",
      "\n",
      "NO13: Make(1) a(2) gluten-free(3) sandwich(4) with(5) gluten-free(6) cheese(7) and(8) corn(9) bread.(10) \n",
      "<11>  Make (sandwich, cheese, corn)    \n",
      "\n",
      "NO14: Put(1) gluten-free(2) sandwich(3) on(4) a(5) tray.(6) \n",
      "<12>  Put (sandwich)    \n",
      "\n",
      "NO15: Move(1) a(2) tray(3) the(4) kitchen(5) to(6) the(7) table5.(8) \n",
      "<13>  Move (tray)    \n",
      "\n",
      "NO16: Serve(1) gluten-free(2) sandwich(3) to(4) Jeff.(5) \n",
      "<14>  Serve (sandwich)    \n",
      "\n",
      "NO17: Move(1) a(2) tray(3) back(4) from(5) table5(6) to(7) the(8) kitchen.(9) \n",
      "<15>  Move (tray)    \n",
      "\n",
      "NO18: Make(1) a(2) gluten-free(3) sandwich(4) with(5) gluten-free(6) cheese(7) and(8) corn(9) bread.(10) \n",
      "<16>  Make (sandwich, cheese, corn)    \n",
      "\n",
      "NO19: Put(1) gluten-free(2) sandwich(3) on(4) a(5) tray.(6) \n",
      "<17>  Put (sandwich)    \n",
      "\n",
      "NO20: Make(1) a(2) sandwich(3) with(4) cheese(5) and(6) wheat(7) bread(8) \n",
      "<18>  Make (sandwich, cheese)    \n",
      "\n",
      "NO21: Put(1) sandwich(2) on(3) tray7.(4) \n",
      "<19>  Put (sandwich)    \n",
      "\n",
      "NO22: Move(1) a(2) tray(3) from(4) the(5) kitchen(6) to(7) the(8) table-5.(9) \n",
      "<20>  Move (tray)    \n",
      "\n",
      "NO23: Serve(1) gluten-free(2) sandwich(3) to(4) Nirmal.(5) \n",
      "<21>  Serve (sandwich)    \n",
      "\n",
      "NO24: Move(1) a(2) tray(3) back(4) from(5) table5(6) to(7) the(8) kitchen.(9) \n",
      "<22>  Move (tray)    \n",
      "\n",
      "NO25: Move(1) tray7(2) from(3) kitchen(4) to(5) the(6) table1(7) \n",
      "<23>  Move (tray7)    \n",
      "\n",
      "NO26: Serve(1) gluten-free(2) sandwich(3) to(4) Kanav.(5) \n",
      "<24>  Serve (sandwich)    \n",
      "\n",
      "NO27: Move(1) tray7(2) back(3) from(4) table1(5) to(6) the(7) kitchen.(8) \n",
      "<25>  Move (tray7)    \n",
      "\n",
      "===========================\n",
      "\n",
      "Make (sandwich, cheese, corn),Put (sandwich),Move (tray),Serve (sandwich),Move (tray),Make (sandwich, cheese),Put (sandwich),Move (tray),Serve (sandwich),Move (tray),Make (sandwich, cheese, corn),Put (sandwich),Move (tray),Serve (sandwich),Move (tray),Make (sandwich, cheese, corn),Put (sandwich),Make (sandwich, cheese),Put (sandwich),Move (tray),Serve (sandwich),Move (tray),Move (tray7),Serve (sandwich),Move (tray7)\n"
     ]
    }
   ],
   "source": [
    "# don't forget to switch the dataset between cooking and wikihow\n",
    "!python -W ignore main_ceasdrl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the domain model in PDDL using iLOCM\n",
    "\n",
    "**interactive-LOCM**\n",
    "This code combines LOCM1 and LOCM2 algorithms and is last part of the pipeline that I use in my thesis to generate PDDL models from instructional texts.\n",
    "\n",
    "- Step 0: Preprocess: Lemmatize, Coref resolve, action override rename and replacing empty parameters.\n",
    "- Step 1: Find classes and make transition graphs.\n",
    "- Step 2: Get transistion sets from LOCM2 algorithm\n",
    "- Step 3: Create FSMs\n",
    "- Step 4: Perform Zero Analysis and add new FSM if necessary.\n",
    "- Step 5: Create and test hypothesis for state parameters\n",
    "- Step 6: Create and merge state parameters\n",
    "- Step 7: Remove parameter flaws\n",
    "- Step 8: Extract static preconditions\n",
    "- Step 9: Form action schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "from IPython.display import display, Markdown\n",
    "from ipycytoscape import *\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"ilocm_input/\"+fname\n",
    "domain_name = input_file_name.split('/')[-1].split('.')[0] #domain name is the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "childsnack_domain\n"
     ]
    }
   ],
   "source": [
    "print(domain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(input_file_name):\n",
    "    '''\n",
    "    Read the input data and return list of action sequences.\n",
    "    Each sequence is a list of action-argumentlist tuples.\n",
    "    '''\n",
    "    file = open(input_file_name, 'r')\n",
    "    sequences = []\n",
    "    for line in file:\n",
    "        \n",
    "        actions = []\n",
    "        arguments = []\n",
    "        if line and not line.isspace() and len(line)>1:\n",
    "            sequence = line.rstrip(\"\\n\\r\").lstrip(\"\\n\\r\").lower() \n",
    "            action_defs = sequence.split(\"),\")\n",
    "\n",
    "            for action_def in action_defs:\n",
    "                action = action_def.split('(')[0].strip(\")\\n\\r\").strip()\n",
    "                argument = action_def.split('(')[1].strip(\")\\n\\r\")\n",
    "                actions.append(action.translate(str.maketrans('', '', string.punctuation)))\n",
    "                argument_list = argument.split(',')\n",
    "                argument_list = [x.strip() for x in argument_list]\n",
    "                #argument_list.insert(0,'zero')\n",
    "                arguments.append(argument_list)\n",
    "                \n",
    "            \n",
    "            actarg_tuples = zip(actions,arguments)\n",
    "            sequences.append(list(actarg_tuples))\n",
    "    return sequences\n",
    "\n",
    "def print_sequences(sequences):\n",
    "    for seq in sequences:\n",
    "        for index,action in enumerate(seq):\n",
    "            print(str(index) + \": \" + str(action))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('make', ['gluten-free', 'sandwich'])\n",
      "1: ('put', ['gluten-free', 'sandwich'])\n",
      "2: ('move', ['tray'])\n",
      "3: ('serve', ['sandwich'])\n",
      "4: ('move', ['tray'])\n",
      "5: ('make', ['sandwich'])\n",
      "6: ('put', ['sandwich'])\n",
      "7: ('move', ['tray'])\n",
      "8: ('serve', ['sandwich'])\n",
      "9: ('move', ['tray'])\n",
      "10: ('make', ['gluten-free', 'sandwich'])\n",
      "11: ('put', ['sandwich'])\n",
      "12: ('move', ['tray'])\n",
      "13: ('serve', ['sandwich'])\n",
      "14: ('move', ['tray'])\n",
      "15: ('make', ['gluten-free', 'sandwich'])\n",
      "16: ('put', ['sandwich'])\n",
      "17: ('make', ['sandwich'])\n",
      "18: ('put', ['sandwich'])\n",
      "19: ('move', ['tray'])\n",
      "20: ('serve', ['sandwich'])\n",
      "21: ('move', ['tray'])\n",
      "22: ('move', ['kitchen'])\n",
      "23: ('serve', ['sandwich'])\n",
      "24: ('move', ['tray-7'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequences = read_file(input_file_name)\n",
    "print_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize action sequences by lemmatization of extracted actions and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('make', ['gluten-free', 'sandwich'])\n",
      "1: ('put', ['gluten-free', 'sandwich'])\n",
      "2: ('move', ['tray'])\n",
      "3: ('serve', ['sandwich'])\n",
      "4: ('move', ['tray'])\n",
      "5: ('make', ['sandwich'])\n",
      "6: ('put', ['sandwich'])\n",
      "7: ('move', ['tray'])\n",
      "8: ('serve', ['sandwich'])\n",
      "9: ('move', ['tray'])\n",
      "10: ('make', ['gluten-free', 'sandwich'])\n",
      "11: ('put', ['sandwich'])\n",
      "12: ('move', ['tray'])\n",
      "13: ('serve', ['sandwich'])\n",
      "14: ('move', ['tray'])\n",
      "15: ('make', ['gluten-free', 'sandwich'])\n",
      "16: ('put', ['sandwich'])\n",
      "17: ('make', ['sandwich'])\n",
      "18: ('put', ['sandwich'])\n",
      "19: ('move', ['tray'])\n",
      "20: ('serve', ['sandwich'])\n",
      "21: ('move', ['tray'])\n",
      "22: ('move', ['kitchen'])\n",
      "23: ('serve', ['sandwich'])\n",
      "24: ('move', ['tray-7'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normalize the words by lemmatization\n",
    "# ps = PorterStemmer()\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "new_sequences = []\n",
    "\n",
    "for seq in sequences:\n",
    "    acts = []\n",
    "    arg_lists = []\n",
    "    for index,action in enumerate(seq):\n",
    "        act = wordnet_lemmatizer.lemmatize(action[0],pos='v')\n",
    "        acts.append(act)\n",
    "        arg_list = [wordnet_lemmatizer.lemmatize(arg, pos='n') for arg in action[1]]\n",
    "        arg_lists.append(arg_list)\n",
    "    act_arg_tups = zip(acts,arg_lists)\n",
    "    new_sequences.append(list(act_arg_tups))\n",
    "\n",
    "\n",
    "print_sequences(new_sequences)\n",
    "sequences = new_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename actions with same name but different arguments by appending a counter to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since action always have one argument, consider '' as an implicit one argument. Not renaming such actions.\n",
    "# renaming 1 or more clashing action prototypes \n",
    "\n",
    "\n",
    "all_tuples_in_all_seqs = []\n",
    "for seq in sequences:\n",
    "    for index,action in enumerate(seq):\n",
    "        all_tuples_in_all_seqs.append((action[0],len(action[1])))\n",
    "        \n",
    "all_act_len_set = set(all_tuples_in_all_seqs) # set of all actions with their arglist lens\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "for k, v in all_act_len_set:\n",
    "    d[k].append(v) #dictionary of list of lens for each key\n",
    "\n",
    "# keys with list len > 1 have clashing action names\n",
    "clashing_action_tuples = []     \n",
    "for k,v in d.items():\n",
    "    if len(d[k]) > 1:\n",
    "        for index,val in enumerate(d[k]):\n",
    "            if index > 0:\n",
    "                clashing_action_tuples.append((k,val,index))\n",
    "                \n",
    "\n",
    "# replace all clashing action tuples in original sequences\n",
    "\n",
    "\n",
    "for clashing_tup in clashing_action_tuples:\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for j, actarg_tup in enumerate(seq):\n",
    "            if (clashing_tup[0] == actarg_tup[0]) and clashing_tup[1] == len(actarg_tup[1]):\n",
    "                sequences[i][j] = (sequences[i][j][0]+str(clashing_tup[2]), sequences[i][j][1])\n",
    "                \n",
    "\n",
    "# replace all '' parameters with '#'\n",
    "for i, seq in enumerate(sequences):\n",
    "    for j, actarg_tup in enumerate(seq):\n",
    "        sequences[i][j] = (sequences[i][j][0], ['#' if x=='' else x for x in sequences[i][j][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('make1', ['gluten-free', 'sandwich'])\n",
      "1: ('put1', ['gluten-free', 'sandwich'])\n",
      "2: ('move', ['tray'])\n",
      "3: ('serve', ['sandwich'])\n",
      "4: ('move', ['tray'])\n",
      "5: ('make', ['sandwich'])\n",
      "6: ('put', ['sandwich'])\n",
      "7: ('move', ['tray'])\n",
      "8: ('serve', ['sandwich'])\n",
      "9: ('move', ['tray'])\n",
      "10: ('make1', ['gluten-free', 'sandwich'])\n",
      "11: ('put', ['sandwich'])\n",
      "12: ('move', ['tray'])\n",
      "13: ('serve', ['sandwich'])\n",
      "14: ('move', ['tray'])\n",
      "15: ('make1', ['gluten-free', 'sandwich'])\n",
      "16: ('put', ['sandwich'])\n",
      "17: ('make', ['sandwich'])\n",
      "18: ('put', ['sandwich'])\n",
      "19: ('move', ['tray'])\n",
      "20: ('serve', ['sandwich'])\n",
      "21: ('move', ['tray'])\n",
      "22: ('move', ['kitchen'])\n",
      "23: ('serve', ['sandwich'])\n",
      "24: ('move', ['tray-7'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_sequences(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Find classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actions\n",
      "{'make', 'put', 'move', 'put1', 'make1', 'serve'}\n",
      "\n",
      "Arguments/Objects\n",
      "{'tray', 'kitchen', 'sandwich', 'tray-7', 'gluten-free'}\n"
     ]
    }
   ],
   "source": [
    "transitions = set() # A transition is denoted by action_name + argument position\n",
    "arguments = set()\n",
    "actions = set()\n",
    "for seq in sequences:\n",
    "    for actarg_tuple in seq:\n",
    "        actions.add(actarg_tuple[0])\n",
    "        for j, arg in enumerate(actarg_tuple[1]):\n",
    "            transitions.add(actarg_tuple[0]+\".\"+str(j))\n",
    "            arguments.add(arg)\n",
    "\n",
    "print(\"\\nActions\")\n",
    "print(actions)\n",
    "# print(\"\\nTransitions\")\n",
    "# print(transitions)\n",
    "print(\"\\nArguments/Objects\")\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actarg_dictionary(sequences):\n",
    "    d = defaultdict(list)\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            d[actarg_tuple[0]].append(actarg_tuple[1])\n",
    "    return d\n",
    "d = get_actarg_dictionary(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class util functions.\n",
    "def get_classes(d):\n",
    "    # TODO incorporate word similarity in get classes.\n",
    "    c = defaultdict(set)\n",
    "    for k,v in d.items():\n",
    "        for arg_list in v:\n",
    "            for i,object in enumerate(arg_list):\n",
    "                c[k,i].add(object)\n",
    "\n",
    "    sets = c.values()\n",
    "    classes = []\n",
    "    # remove duplicate classes\n",
    "    for s in sets:\n",
    "        if s not in classes:\n",
    "            classes.append(s)\n",
    "\n",
    "    # now do pairwise intersections of all values. If intersection, combine them; then return the final sets.\n",
    "    classes_copy = list(classes)\n",
    "    while True:\n",
    "        combinations = list(itertools.combinations(classes_copy,2))\n",
    "        intersections_count = 0\n",
    "        for combination in combinations:\n",
    "            if combination[0].intersection(combination[1]):\n",
    "                intersections_count +=1\n",
    "\n",
    "                if combination[0] in classes_copy:\n",
    "                    classes_copy.remove(combination[0])\n",
    "                if combination[1] in classes_copy:\n",
    "                    classes_copy.remove(combination[1])\n",
    "                classes_copy.append(combination[0].union(combination[1]))\n",
    "\n",
    "        if intersections_count==0:\n",
    "            # print(\"no intersections left\")\n",
    "            break\n",
    "\n",
    "    return classes_copy\n",
    "\n",
    "# TODO: Can use better approach here. NER might help.\n",
    "def get_class_names(classes):\n",
    "    # Name the class to first object found ignoring the digits in it\n",
    "    class_names = []\n",
    "    for c in classes:\n",
    "        for object in c:\n",
    "#             object = ''.join([i for i in object if not i.isdigit()])\n",
    "            class_names.append(object)\n",
    "            break\n",
    "    return class_names\n",
    "\n",
    "def get_class_index(arg,classes):\n",
    "    for class_index, c in enumerate(classes):\n",
    "        if arg in c:\n",
    "            return class_index #it is like breaking out of the loop\n",
    "    print(\"Error:class index not found\") #this statement is only executed if class index is not returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorts/Classes\n",
      "[{'gluten-free'}, {'sandwich'}, {'kitchen', 'tray', 'tray-7'}]\n",
      "\n",
      "Extracted class names\n",
      "['gluten-free', 'sandwich', 'kitchen']\n"
     ]
    }
   ],
   "source": [
    "classes = get_classes(d) #sorts of object\n",
    "print(\"\\nSorts/Classes\")\n",
    "print(classes)\n",
    "\n",
    "class_names = get_class_names(classes)\n",
    "print(\"\\nExtracted class names\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT 1: Enter Correct Class names\n",
    "Editing the extracted class names to more readable object classes will make the final PDDL model more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renamed class names\n",
      "['gluten-free', 'sandwich', 'kitchen']\n"
     ]
    }
   ],
   "source": [
    "############ (Optional) User Input ############\n",
    "# Give user an option to change class names.\n",
    "# class_names[0] = 'rocket'\n",
    "\n",
    "#tyre\n",
    "# class_names[0] = 'Jack'\n",
    "# class_names[1] = 'Boot'\n",
    "# class_names[2] = 'Wheel'\n",
    "# class_names[3] = 'Hub'\n",
    "# class_names[4] = 'Wrench'\n",
    "# class_names[5] = 'Nut'\n",
    "\n",
    "#driverlog\n",
    "# class_names[0] = 'Driver'\n",
    "# class_names[1] = 'Truck'\n",
    "# class_names[2] = 'Package'\n",
    "# class_names[3] = 'Location'\n",
    "\n",
    "# #blocksworld\n",
    "# class_names[0] = 'Block'\n",
    "# class_names[1] = 'Gripper'\n",
    "\n",
    "print(\"\\nRenamed class names\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Assumptions of LOCM2**\n",
    "- Each object of a same class undergoes similar kind of transition.\n",
    "- Objects of same class in a same action undergo similar kind of transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actions\n",
      "{'make', 'put', 'move', 'put1', 'make1', 'serve'}\n",
      "\n",
      "Transitions\n",
      "{'put1.sandwich.1', 'move.kitchen.0', 'serve.sandwich.0', 'make1.gluten-free.0', 'make.sandwich.0', 'put.sandwich.0', 'put1.gluten-free.0', 'make1.sandwich.1'}\n",
      "\n",
      "Arguments/Objects\n",
      "{'tray', 'kitchen', 'sandwich', 'tray-7', 'gluten-free'}\n"
     ]
    }
   ],
   "source": [
    "# change transitions to be more meaningful by incorporating class_names.\n",
    "full_transitions = set()\n",
    "for seq in sequences:\n",
    "    for actarg_tuple in seq:\n",
    "        actions.add(actarg_tuple[0])\n",
    "        for j, arg in enumerate(actarg_tuple[1]):\n",
    "            full_transitions.add(actarg_tuple[0]+\".\"+class_names[get_class_index(arg,classes)]+'.'+str(j))\n",
    "            arguments.add(arg)\n",
    "\n",
    "print(\"\\nActions\")\n",
    "print(actions)\n",
    "print(\"\\nTransitions\")\n",
    "print(full_transitions)\n",
    "print(\"\\nArguments/Objects\")\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Actions: 6,\n",
      "Number of unique transitions: 8,\n",
      "Number of unique objects (arguments): 5,\n",
      "Number of classes/sorts: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of Actions: {},\\nNumber of unique transitions: {},\\nNumber of unique objects (arguments): {},\\nNumber of classes/sorts: {}\".format(len(actions), len(transitions), len(arguments), len(classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Transition graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def empty_directory(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            # elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))\n",
    "\n",
    "def print_table(matrix):\n",
    "    display(tabulate(matrix, headers='keys', tablefmt='html'))\n",
    "    \n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save graphs in graphml format (used in cytoscape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(graphs, domain_name):\n",
    "    adjacency_matrix_list = [] # list of adjacency matrices per class\n",
    "    \n",
    "    for index, G in enumerate(graphs):\n",
    "        nx.write_graphml(G, \"output/\"+ domain_name + \"/\" +  class_names[index] + \".graphml\")\n",
    "        df = nx.to_pandas_adjacency(G, nodelist=G.nodes(), dtype=int)\n",
    "        adjacency_matrix_list.append(df)\n",
    "#         print_table(df)\n",
    "    return adjacency_matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cytographs(graphs, domain_name, aml):\n",
    "    cytoscapeobs = []\n",
    "    for index, G in enumerate(graphs):\n",
    "            cytoscapeobj = CytoscapeWidget()\n",
    "            cytoscapeobj.graph.add_graph_from_networkx(G)\n",
    "            edge_list = list()\n",
    "            for source, target, data in G.edges(data=True):\n",
    "                edge_instance = Edge()\n",
    "                edge_instance.data['source'] = source\n",
    "                edge_instance.data['target'] = target\n",
    "                for k, v in data.items():\n",
    "                    cyto_attrs = ['group', 'removed', 'selected', 'selectable',\n",
    "                        'locked', 'grabbed', 'grabbable', 'classes', 'position', 'data']\n",
    "                    if k in cyto_attrs:\n",
    "                        setattr(edge_instance, k, v)\n",
    "                    else:\n",
    "                        edge_instance.data[k] = v\n",
    "                    edge_list.append(edge_instance)\n",
    "            cytoscapeobj.graph.edges = edge_list\n",
    "#             cytoscapeobj.graph.add_graph_from_df(aml[index],aml[index].columns.tolist())\n",
    "            cytoscapeobs.append(cytoscapeobj)\n",
    "#             print(cytoscapeobj)\n",
    "            printmd('## class **'+class_names[index]+'**')\n",
    "            print_table(aml[index])\n",
    "    #         print(\"Nodes:{}\".format(G.nodes()))\n",
    "    #         print(\"Edges:{}\".format(G.edges()))\n",
    "            cytoscapeobj.set_style([{\n",
    "                            'width':400,\n",
    "                            'height':400,\n",
    "\n",
    "                            'selector': 'node',\n",
    "                            'style': {\n",
    "                                'label': 'data(id)',\n",
    "                                'font-family': 'helvetica',\n",
    "                                'font-size': '8px',\n",
    "                                'background-color': '#11479e',\n",
    "                                'height':'10px',\n",
    "                                'width':'10px',\n",
    "\n",
    "\n",
    "                                }\n",
    "\n",
    "                            },\n",
    "                            {\n",
    "                            'selector': 'node:parent',\n",
    "                            'css': {\n",
    "                                'background-opacity': 0.333,\n",
    "                                'background-color': '#bbb'\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                            'selector': '$node > node',\n",
    "                            'css': {\n",
    "                                'padding-top': '10px',\n",
    "                                'padding-left': '10px',\n",
    "                                'padding-bottom': '10px',\n",
    "                                'padding-right': '10px',\n",
    "                                'text-valign': 'top',\n",
    "                                'text-halign': 'center',\n",
    "                                'background-color': '#bbb'\n",
    "                              }\n",
    "                            },\n",
    "                           {\n",
    "                                'selector': 'edge',\n",
    "\n",
    "                                'style': {\n",
    "                                    'label':'data(weight)',\n",
    "                                    'width': 1,\n",
    "                                    'line-color': '#9dbaea',\n",
    "                                    'target-arrow-shape': 'triangle',\n",
    "                                    'target-arrow-color': '#9dbaea',\n",
    "                                    'arrow-scale': 0.5,\n",
    "                                    'curve-style': 'bezier',\n",
    "                                    'font-family': 'helvetica',\n",
    "                                    'font-size': '8px',\n",
    "                                    'text-valign': 'top',\n",
    "                                    'text-halign':'center'\n",
    "                                }\n",
    "                            },\n",
    "                            ])\n",
    "            cytoscapeobj.max_zoom = 4.0\n",
    "            cytoscapeobj.min_zoom = 0.5\n",
    "            display(cytoscapeobj)\n",
    "    return cytoscapeobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build transitions graphs and call save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_transition_graphs(classes, domain_name, class_names):\n",
    "    # There should be a graph for each class of objects.\n",
    "    graphs = []\n",
    "    # Initialize all graphs empty\n",
    "    for sort in classes:\n",
    "        graphs.append(nx.DiGraph())\n",
    "\n",
    "    consecutive_transition_lists = [] #list of consecutive transitions per object instance per sequence.\n",
    "\n",
    "    for m, arg in enumerate(arguments):  # for all arguments (objects found in sequences)\n",
    "        for n, seq in enumerate(sequences):  # for all sequences\n",
    "            consecutive_transition_list = list()  # consecutive transition list for a sequence and an object (arg)\n",
    "            for i, actarg_tuple in enumerate(seq):\n",
    "                for j, arg_prime in enumerate(actarg_tuple[1]):  # for all arguments in actarg tuples\n",
    "                    if arg == arg_prime:  # if argument matches arg\n",
    "                        node = actarg_tuple[0] + \".\" +  str(j)\n",
    "                        # node = actarg_tuple[0] +  \".\" + class_names[get_class_index(arg,classes)] + \".\" +  str(j)  # name the node of graph which represents a transition\n",
    "                        consecutive_transition_list.append(node)  # add node to the cons_transition for sequence and argument\n",
    "\n",
    "                        # for each class append the nodes to the graph of that class\n",
    "                        class_index = get_class_index(arg_prime, classes)  # get index of class to which the object belongs to\n",
    "                        graphs[class_index].add_node(node)  # add node to the graph of that class\n",
    "\n",
    "            consecutive_transition_lists.append([n, arg, consecutive_transition_list])\n",
    "\n",
    "    # print(consecutive_transition_lists)\n",
    "    # for all consecutive transitions add edges to the appropriate graphs.\n",
    "    for cons_trans_list in consecutive_transition_lists:\n",
    "        # print(cons_trans_list)\n",
    "        seq_no = cons_trans_list[0]  # get sequence number\n",
    "        arg = cons_trans_list[1]  # get argument\n",
    "        class_index = get_class_index(arg, classes)  # get index of class\n",
    "        # add directed edges to graph of that class\n",
    "        for i in range(0, len(cons_trans_list[2]) - 1):\n",
    "                if graphs[class_index].has_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1]):\n",
    "                    graphs[class_index][cons_trans_list[2][i]][cons_trans_list[2][i + 1]]['weight'] += 1\n",
    "                else:\n",
    "                    graphs[class_index].add_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1], weight=1)\n",
    "\n",
    "\n",
    "    \n",
    "    # make directory if doesn't exist\n",
    "    dirName = \"output/\"+ domain_name\n",
    "    if not os.path.exists(dirName):\n",
    "        os.makedirs(dirName)\n",
    "        print(\"Directory \", dirName, \" Created \")\n",
    "    else:\n",
    "        print(\"Directory \", dirName, \" already exists\")\n",
    "    empty_directory(dirName)\n",
    "     \n",
    "    # save all the graphs\n",
    "    adjacency_matrix_list = save(graphs, domain_name) # list of adjacency matrices per class\n",
    "    \n",
    "    # plot cytoscape interactive graphs\n",
    "    cytoscapeobs = plot_cytographs(graphs,domain_name, adjacency_matrix_list)\n",
    "    \n",
    "    return adjacency_matrix_list, graphs, cytoscapeobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transition Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## CHILDSNACK_DOMAIN"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  output/childsnack_domain  Created \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## class **gluten-free**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  make1.0</th><th style=\"text-align: right;\">  put1.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>make1.0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td>put1.0 </td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  make1.0</th><th style=\"text-align: right;\">  put1.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>make1.0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\\n<tr><td>put1.0 </td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bb1e3d72ea487f9897e3e3455ccf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 400, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## class **sandwich**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  serve.0</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  put.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>make1.1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put1.1 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>serve.0</td><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>make.0 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put.0  </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  serve.0</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  put.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>make1.1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put1.1 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>serve.0</td><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>make.0 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put.0  </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b6c9fdb49645a19d620f688370f8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 400, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## class **kitchen**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71806c3f033e4421bdc17a3ddcf40a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 400, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Build weighted directed graphs for transitions.\n",
    "printmd(\"## \"+ domain_name.upper())\n",
    "adjacency_matrix_list, graphs, cytoscapeobjs = build_and_save_transition_graphs(classes, domain_name, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT 2: Edit transition graphs\n",
    "For meaningful LOCM models, here one can edit the transition graphs to make them accurate. However, in the paper we don't do that in order to estimate what kind of models are learned automatically from natural language data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1. **You can add or delete nodes/edges in transition graphs by following methods like add_node, delete_edges shown in the following library.**\n",
    "https://github.com/QuantStack/ipycytoscape/blob/master/ipycytoscape/cytoscape.py\n",
    "\n",
    "Option 2. **Alternatively you can use the saved .graphml file. Open it up in Cytoscape, edit it within the GUI and load that graph into the graphs list.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get Transition Sets from LOCM2\n",
    "\n",
    "**Algorithm**: LOCM2\n",
    "\n",
    "**Input** : \n",
    "- T_all = set of observed transitions for a sort/class\n",
    "- H : Set of holes - each hole is a set of two transitions.\n",
    "- P : Set of pairs <t1,t2> i.e. consecutive transitions.\n",
    "- E : Set of example sequences of actions.\n",
    "\n",
    "**Output**:\n",
    "- S : Set of transition sets.\n",
    "### Finding holes\n",
    "Holes are transitions that LOCM1 will assume to be true due to the flaw of overgeneralizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix_with_holes(adjacency_matrix_list):\n",
    "    adjacency_matrix_list_with_holes = []\n",
    "    for index,adjacency_matrix in enumerate(adjacency_matrix_list):\n",
    "        # print(\"\\n ROWS ===========\")\n",
    "        df = adjacency_matrix.copy()\n",
    "        df1 = adjacency_matrix.copy()\n",
    "\n",
    "        # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "        for i in range(df.shape[0] - 1):\n",
    "            for j in range(i+1, df.shape[0]):\n",
    "                idx1, idx2 = i, j\n",
    "                row1, row2 = df.iloc[idx1,:], df.iloc[idx2, :] #we have now all pairs of rows\n",
    "\n",
    "                common_values_flag = False #for each two rows we have a common_values_flag\n",
    "\n",
    "                # if there is a common value between two rows, turn common value flag to true\n",
    "                for col in range(row1.shape[0]):\n",
    "                    if row1.iloc[col] > 0 and row2.iloc[col] > 0:\n",
    "                        common_values_flag = True\n",
    "                        break\n",
    "\n",
    "                # now if two rows have common values, we need to check for holes.\n",
    "                if common_values_flag:\n",
    "                    for col in range(row1.shape[0]):\n",
    "                        if row1.iloc[col] > 0 and row2.iloc[col] == 0:\n",
    "                            df1.iloc[idx2,col] = 'hole'\n",
    "                        elif row1.iloc[col] == 0 and row2.iloc[col] > 0:\n",
    "                            df1.iloc[idx1, col] = 'hole'\n",
    "\n",
    "        adjacency_matrix_list_with_holes.append(df1)\n",
    "    return adjacency_matrix_list_with_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  make1.0</th><th style=\"text-align: right;\">  put1.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>make1.0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td>put1.0 </td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  make1.0</th><th style=\"text-align: right;\">  put1.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>make1.0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td></tr>\\n<tr><td>put1.0 </td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### HOLES: gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  make1.0</th><th>put1.0  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>make1.0</td><td style=\"text-align: right;\">        1</td><td>1       </td></tr>\n",
       "<tr><td>put1.0 </td><td style=\"text-align: right;\">        1</td><td>hole    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  make1.0</th><th>put1.0  </th></tr>\\n</thead>\\n<tbody>\\n<tr><td>make1.0</td><td style=\"text-align: right;\">        1</td><td>1       </td></tr>\\n<tr><td>put1.0 </td><td style=\"text-align: right;\">        1</td><td>hole    </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  serve.0</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  put.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>make1.1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put1.1 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>serve.0</td><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>make.0 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put.0  </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  serve.0</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  put.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>make1.1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put1.1 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>serve.0</td><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>make.0 </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put.0  </td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### HOLES: sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>make1.1  </th><th>put1.1  </th><th style=\"text-align: right;\">  serve.0</th><th>make.0  </th><th style=\"text-align: right;\">  put.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>make1.1</td><td>0        </td><td>1       </td><td style=\"text-align: right;\">        0</td><td>0       </td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put1.1 </td><td>hole     </td><td>0       </td><td style=\"text-align: right;\">        1</td><td>hole    </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>serve.0</td><td>2        </td><td>0       </td><td style=\"text-align: right;\">        1</td><td>1       </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>make.0 </td><td>0        </td><td>hole    </td><td style=\"text-align: right;\">        0</td><td>0       </td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put.0  </td><td>hole     </td><td>0       </td><td style=\"text-align: right;\">        3</td><td>1       </td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th>make1.1  </th><th>put1.1  </th><th style=\"text-align: right;\">  serve.0</th><th>make.0  </th><th style=\"text-align: right;\">  put.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>make1.1</td><td>0        </td><td>1       </td><td style=\"text-align: right;\">        0</td><td>0       </td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put1.1 </td><td>hole     </td><td>0       </td><td style=\"text-align: right;\">        1</td><td>hole    </td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>serve.0</td><td>2        </td><td>0       </td><td style=\"text-align: right;\">        1</td><td>1       </td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>make.0 </td><td>0        </td><td>hole    </td><td style=\"text-align: right;\">        0</td><td>0       </td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put.0  </td><td>hole     </td><td>0       </td><td style=\"text-align: right;\">        3</td><td>1       </td><td style=\"text-align: right;\">      0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "#### HOLES: kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adjacency_matrix_list_with_holes = get_adjacency_matrix_with_holes(adjacency_matrix_list)\n",
    "\n",
    "# Printing FSM matrices with and without holes\n",
    "for index,adjacency_matrix in enumerate(adjacency_matrix_list):\n",
    "    printmd(\"\\n#### \" + class_names[index] )\n",
    "    print_table(adjacency_matrix)\n",
    "\n",
    "    printmd(\"\\n#### HOLES: \" + class_names[index])\n",
    "    print_table(adjacency_matrix_list_with_holes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#holes in class gluten-free:1\n",
      "#holes in class sandwich:3\n",
      "#holes in class kitchen:0\n"
     ]
    }
   ],
   "source": [
    "# Create list of set of holes per class (H)\n",
    "holes_per_class = []\n",
    "\n",
    "for index,df in enumerate(adjacency_matrix_list_with_holes):\n",
    "    holes = set()\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[1]):\n",
    "            if df.iloc[i,j] == 'hole':\n",
    "                holes.add(frozenset({df.index[i] , df.columns[j]}))\n",
    "    holes_per_class.append(holes)\n",
    "for i, hole in enumerate(holes_per_class):\n",
    "    print(\"#holes in class \" + class_names[i]+\":\" + str(len(hole)))\n",
    "#     for h in hole:\n",
    "#         print(list(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T_all - Set of observed transitions for a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of transitions per class (T_all). It is just a set of transitions that occur for a class.\n",
    "transitions_per_class = []\n",
    "for index, df in enumerate(adjacency_matrix_list_with_holes):\n",
    "    transitions_per_class.append(df.columns.values)\n",
    "# for i, transition in enumerate(transitions_per_class):\n",
    "#     print('{}:{}'.format(class_names[i], transition))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P - set of pairs <t1,t2> (consecutive transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consecutive_transitions_per_class(adjacency_matrix_list_with_holes):\n",
    "    consecutive_transitions_per_class = []\n",
    "    for index, df in enumerate(adjacency_matrix_list_with_holes):\n",
    "        consecutive_transitions = set()  # for a class\n",
    "        for i in range(df.shape[0]):\n",
    "            for j in range(df.shape[1]):\n",
    "                if df.iloc[i, j] != 'hole':\n",
    "                    if df.iloc[i, j] > 0:\n",
    "#                         print(\"(\" + df.index[i] + \",\" + df.columns[j] + \")\")\n",
    "                        consecutive_transitions.add((df.index[i], df.columns[j]))\n",
    "        consecutive_transitions_per_class.append(consecutive_transitions)\n",
    "    return consecutive_transitions_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create list of consecutive transitions per class (P). If value is not null, ordered pair i,j would be consecutive transitions per class\n",
    "consecutive_transitions_per_class = get_consecutive_transitions_per_class(adjacency_matrix_list_with_holes)\n",
    "# printmd(\"###  Consecutive transitions per class\")\n",
    "# for i, transition in enumerate(consecutive_transitions_per_class):\n",
    "#     printmd(\"#### \"+class_names[i]+\":\")\n",
    "#     for x in list(transition):\n",
    "#         print(x)\n",
    "# #     print('{}:{}'.format(class_names[i], transition))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Well Formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_well_formed(subset_df):\n",
    "    # got the adjacency matrix subset\n",
    "    df = subset_df.copy()\n",
    "    well_formed_flag = True\n",
    "    \n",
    "    \n",
    "    if (df == 0).all(axis=None): # all elements are zero\n",
    "        well_formed_flag = False\n",
    "        \n",
    "    # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "    for i in range(0, df.shape[0]-1):\n",
    "        for j in range(i + 1, df.shape[0]):\n",
    "            print(i,j)\n",
    "            idx1, idx2 = i, j\n",
    "            row1, row2 = df.iloc[idx1, :], df.iloc[idx2, :]  # we have now all pairs of rows\n",
    "\n",
    "            common_values_flag = False  # for each two rows we have a common_values_flag\n",
    "\n",
    "            # if there is a common value between two rows, turn common value flag to true\n",
    "            for col in range(row1.shape[0]):\n",
    "                if row1.iloc[col] > 0 and row2.iloc[col] > 0:\n",
    "                    common_values_flag = True\n",
    "                    break\n",
    "          \n",
    "            if common_values_flag:\n",
    "                for col in range(row1.shape[0]): # check for holes if common value\n",
    "                    if row1.iloc[col] > 0 and row2.iloc[col] == 0:\n",
    "                        well_formed_flag = False\n",
    "                    elif row1.iloc[col] == 0 and row2.iloc[col] > 0:\n",
    "                        well_formed_flag = False\n",
    "    \n",
    "    if not well_formed_flag:\n",
    "        return False\n",
    "    elif well_formed_flag:\n",
    "        return True\n",
    "     \n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Valid Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid(subset_df,consecutive_transitions_per_class):\n",
    "    \n",
    "    # Note: Essentially we check validity against P instead of E. \n",
    "    # In the paper of LOCM2, it isn't mentioned how to check against E.\n",
    "    \n",
    "    # Reasoning: If we check against all consecutive transitions per class, \n",
    "    # we essentially check against all example sequences.\n",
    "    # check the candidate set which is well-formed (subset df against all consecutive transitions)\n",
    "\n",
    "    # got the adjacency matrix subset\n",
    "    df = subset_df.copy()\n",
    "\n",
    "    # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[0]):\n",
    "            if df.iloc[i,j] > 0:\n",
    "                valid_val_flag = False\n",
    "                ordered_pair = (df.index[i], df.columns[j])\n",
    "                for ct_list in consecutive_transitions_per_class:\n",
    "                    for ct in ct_list:\n",
    "                        if ordered_pair == ct:\n",
    "                            valid_val_flag=True\n",
    "                # if after all iteration ordered pair is not found, mark the subset as invalid.\n",
    "                if not valid_val_flag:\n",
    "                    return False\n",
    "                \n",
    "    # return True if all ordered pairs found.\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOCM2 transition sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Getting transitions sets for each class using LOCM2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 holes\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Hole 1: {'put1.0'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Final transition set list"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'put1.0', 'make1.0'}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 holes\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Hole 1: {'make1.1', 'put.0'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Checking candidate set *{'put1.1', 'make1.1', 'put.0'}* of class **sandwich** for well formedness and Validity"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put.0  </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put.0  </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "1 2\n",
      "This subset is well-formed.\n",
      "This subset is valid.\n",
      "Adding this subset {'put1.1', 'make1.1', 'put.0'} to the locm2 transition set.\n",
      "Hole that is covered now:\n",
      "['make1.1', 'put.0']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Hole 2: {'put1.1', 'make.0'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Checking candidate set *{'put1.1', 'make.0', 'make1.1'}* of class **sandwich** for well formedness and Validity"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  make1.1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>make.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  make1.1</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\\n<tr><td>make.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\\n<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "1 2\n",
      "This subset is well-formed.\n",
      "This subset is valid.\n",
      "Adding this subset {'put1.1', 'make.0', 'make1.1'} to the locm2 transition set.\n",
      "Hole that is covered now:\n",
      "['put1.1', 'make.0']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Hole 3: {'put1.1', 'make1.1'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hole {'put1.1', 'make1.1'} is already covered."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'put1.1', 'make1.1', 'put.0'}, {'put1.1', 'make.0', 'make1.1'}]\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[{'put1.1', 'make1.1', 'put.0'}, {'put1.1', 'make.0', 'make1.1'}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Final transition set list"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'put1.1', 'make1.1', 'put.0'}, {'put1.1', 'make.0', 'make1.1'}, {'put1.1', 'put.0', 'make.0', 'make1.1', 'serve.0'}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no holes\n",
      "[]\n",
      "\n",
      "Removed redundancy transition set list\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Final transition set list"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'move.0'}]\n"
     ]
    }
   ],
   "source": [
    "def locm2_get_transition_sets_per_class(holes_per_class, transitions_per_class, consecutive_transitions_per_class):\n",
    "    \"\"\"LOCM 2 Algorithm in the original LOCM2 paper\"\"\"\n",
    "    \n",
    "    # contains Solution Set S for each class.\n",
    "    transition_sets_per_class = []\n",
    "\n",
    "    # for each hole for a class/sort\n",
    "    for index, holes in enumerate(holes_per_class):\n",
    "        class_name = class_names[index]\n",
    "        printmd(\"### \"+  class_name)\n",
    "        \n",
    "        # S\n",
    "        transition_set_list = [] #transition_sets_of_a_class, # intially it's empty\n",
    "        \n",
    "        if len(holes)==0:\n",
    "            print(\"no holes\") # S will contain just T_all\n",
    "        \n",
    "        if len(holes) > 0: # if there are any holes for a class\n",
    "            print(str(len(holes)) + \" holes\")\n",
    "            for ind, hole in enumerate(holes):\n",
    "                printmd(\"#### Hole \" + str(ind + 1) + \": \" + str(set(hole)))\n",
    "                is_hole_already_covered_flag = False\n",
    "                if len(transition_set_list)>0:\n",
    "                    for s_prime in transition_set_list:\n",
    "                        if hole.issubset(s_prime):\n",
    "                            printmd(\"Hole \"+ str(set(hole)) + \" is already covered.\")\n",
    "                            is_hole_already_covered_flag = True\n",
    "                            break\n",
    "                     \n",
    "                # discover a set which includes hole and is well-formed and valid against test data.\n",
    "                # if hole is not covered, do BFS with sets of increasing sizes starting with s=hole\n",
    "                if not is_hole_already_covered_flag: \n",
    "                    h = hole.copy()\n",
    "                    candidate_sets = []\n",
    "                    # all subsets of T_all starting from hole's len +1 to T_all-1.\n",
    "                    for i in range(len(h)+1,len(transitions_per_class[index])): \n",
    "                        subsets = findsubsets(transitions_per_class[index],i) # all subsets of length i\n",
    "\n",
    "                        for s in subsets:\n",
    "                            if h.issubset(s): # if  is subset of s\n",
    "                                candidate_sets.append(set(s))\n",
    "                        \n",
    "                        s_well_formed_and_valid = False\n",
    "                        for s in candidate_sets:\n",
    "                            if len(s)>=i:\n",
    "                                printmd(\"Checking candidate set *\" + str(s) + \"* of class **\" + class_name + \"** for well formedness and Validity\")\n",
    "                                subset_df = adjacency_matrix_list[index].loc[list(s),list(s)]\n",
    "                                print_table(subset_df)\n",
    "\n",
    "                                # checking for well-formedness\n",
    "                                well_formed_flag = False\n",
    "                                well_formed_flag = check_well_formed(subset_df)\n",
    "                                if not well_formed_flag:\n",
    "                                    print(\"This subset is NOT well-formed\")\n",
    "                                    \n",
    "                                elif well_formed_flag:\n",
    "                                    print(\"This subset is well-formed.\")\n",
    "                                    # if well-formed validate across the data E\n",
    "                                    # to remove inappropriate dead-ends\n",
    "                                    valid_against_data_flag = False\n",
    "                                    valid_against_data_flag = check_valid(subset_df, consecutive_transitions_per_class)\n",
    "                                    if not valid_against_data_flag:\n",
    "                                        print(\"This subset is well-formed but invalid against example data\")\n",
    "\n",
    "                                    if valid_against_data_flag:\n",
    "                                        print(\"This subset is valid.\")\n",
    "                                        print(\"Adding this subset \" + str(s) +\" to the locm2 transition set.\")\n",
    "                                        if s not in transition_set_list: # do not allow copies.\n",
    "                                            transition_set_list.append(s)\n",
    "                                        \n",
    "                                        print(\"Hole that is covered now:\")\n",
    "                                        print(list(h))\n",
    "                                        s_well_formed_and_valid = True\n",
    "                                        break \n",
    "                        if s_well_formed_and_valid:\n",
    "                                break\n",
    "                                        \n",
    "                                        \n",
    "\n",
    "        print(transition_set_list)                                    \n",
    "        #step 7 : remove redundant sets S - {s1}\n",
    "        ts_copy = transition_set_list.copy()\n",
    "        for i in range(len(ts_copy)):\n",
    "            for j in range(len(ts_copy)):\n",
    "                if ts_copy[i] < ts_copy[j]: #if subset\n",
    "                    if ts_copy[i] in transition_set_list:\n",
    "                        transition_set_list.remove(ts_copy[i])\n",
    "                elif ts_copy[i] > ts_copy[j]:\n",
    "                    if ts_copy[j] in transition_set_list:\n",
    "                        transition_set_list.remove(ts_copy[j])\n",
    "        print(\"\\nRemoved redundancy transition set list\")\n",
    "        print(transition_set_list)\n",
    "\n",
    "        #step-8: include all-transitions machine, even if it is not well-formed.\n",
    "        transition_set_list.append(set(transitions_per_class[index])) #fallback\n",
    "        printmd(\"#### Final transition set list\")\n",
    "        print(transition_set_list)\n",
    "        transition_sets_per_class.append(transition_set_list)\n",
    "        \n",
    "\n",
    "    return transition_sets_per_class\n",
    "\n",
    "\n",
    "############    LOCM2 #################\n",
    "####    Input ready for LOCM2, Starting LOCM2 algorithm now\n",
    "####    Step 8:  selecting transition sets (TS) [Main LOCM2 Algorithm]\n",
    "printmd(\"### Getting transitions sets for each class using LOCM2\")\n",
    "transition_sets_per_class = locm2_get_transition_sets_per_class(holes_per_class, transitions_per_class, consecutive_transitions_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Algorithm For Induction of State Machines\n",
    "\n",
    "- Input: Action training sequence of length N\n",
    "- Output: Transition Set TS, Object states OS.\n",
    "\n",
    "We already have transition set TS per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cytographs_fsm(graph, domain_name):\n",
    "    cytoscapeobj = CytoscapeWidget()\n",
    "    cytoscapeobj.graph.add_graph_from_networkx(graph)\n",
    "    edge_list = list()\n",
    "    for source, target, data in graph.edges(data=True):\n",
    "        edge_instance = Edge()\n",
    "        edge_instance.data['source'] = source\n",
    "        edge_instance.data['target'] = target\n",
    "        for k, v in data.items():\n",
    "            cyto_attrs = ['group', 'removed', 'selected', 'selectable',\n",
    "                'locked', 'grabbed', 'grabbable', 'classes', 'position', 'data']\n",
    "            if k in cyto_attrs:\n",
    "                setattr(edge_instance, k, v)\n",
    "            else:\n",
    "                edge_instance.data[k] = v\n",
    "            edge_list.append(edge_instance)\n",
    "\n",
    "    cytoscapeobj.graph.edges = edge_list\n",
    "#     print(\"Nodes:{}\".format(graph.nodes()))\n",
    "#     print(\"Edges:{}\".format(graph.edges()))\n",
    "    cytoscapeobj.set_style([{\n",
    "                    'width':400,\n",
    "                    'height':500,\n",
    "\n",
    "                    'selector': 'node',\n",
    "                    'style': {\n",
    "                        'label': 'data(id)',\n",
    "                        'font-family': 'helvetica',\n",
    "                        'font-size': '8px',\n",
    "                        'background-color': '#11479e',\n",
    "                        'height':'10px',\n",
    "                        'width':'10px',\n",
    "\n",
    "\n",
    "                        }\n",
    "\n",
    "                    },\n",
    "                    {\n",
    "                    'selector': 'node:parent',\n",
    "                    'css': {\n",
    "                        'background-opacity': 0.333,\n",
    "                        'background-color': '#bbb'\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                    'selector': '$node > node',\n",
    "                    'css': {\n",
    "                        'padding-top': '10px',\n",
    "                        'padding-left': '10px',\n",
    "                        'padding-bottom': '10px',\n",
    "                        'padding-right': '10px',\n",
    "                        'text-valign': 'top',\n",
    "                        'text-halign': 'center',\n",
    "                        'background-color': '#bbb'\n",
    "                      }\n",
    "                    },\n",
    "                   {\n",
    "                        'selector': 'edge',\n",
    "\n",
    "                        'style': {\n",
    "                            'label':'data(weight)',\n",
    "                            'width': 1,\n",
    "                            'line-color': '#9dbaea',\n",
    "                            'target-arrow-shape': 'triangle',\n",
    "                            'target-arrow-color': '#9dbaea',\n",
    "                            'arrow-scale': 0.5,\n",
    "                            'curve-style': 'bezier',\n",
    "                            'font-family': 'helvetica',\n",
    "                            'font-size': '8px',\n",
    "                            'text-valign': 'top',\n",
    "                            'text-halign':'center'\n",
    "                        }\n",
    "                    },\n",
    "                    ])\n",
    "    cytoscapeobj.max_zoom = 2.0\n",
    "    cytoscapeobj.min_zoom = 0.5\n",
    "    display(cytoscapeobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First make start(t) and end(t) as state for each transition in FSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  put1.0</th><th style=\"text-align: right;\">  make1.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>put1.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td>make1.0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  put1.0</th><th style=\"text-align: right;\">  make1.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>put1.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        1</td></tr>\\n<tr><td>make1.0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        1</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef6622bebce4049abce39389a487ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                                         </th><th style=\"text-align: right;\">  e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0)</td><td style=\"text-align: right;\">                                          1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                                         </th><th style=\"text-align: right;\">  e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0)</td><td style=\"text-align: right;\">                                          1</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:3\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      2</td></tr>\n",
       "<tr><td>put.0  </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  put.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\\n<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      2</td></tr>\\n<tr><td>put.0  </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d955fd0c5554dbfa09682ca4f89943a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                             </th><th style=\"text-align: right;\">  e(put1.1)</th><th style=\"text-align: right;\">  s(make1.1)</th><th style=\"text-align: right;\">  e(make1.1)|s(put1.1)|s(put.0)</th><th style=\"text-align: right;\">  e(put.0)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>e(put1.1)                    </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">         0</td></tr>\n",
       "<tr><td>s(make1.1)                   </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              1</td><td style=\"text-align: right;\">         0</td></tr>\n",
       "<tr><td>e(make1.1)|s(put1.1)|s(put.0)</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">         1</td></tr>\n",
       "<tr><td>e(put.0)                     </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">         0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                             </th><th style=\"text-align: right;\">  e(put1.1)</th><th style=\"text-align: right;\">  s(make1.1)</th><th style=\"text-align: right;\">  e(make1.1)|s(put1.1)|s(put.0)</th><th style=\"text-align: right;\">  e(put.0)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>e(put1.1)                    </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">         0</td></tr>\\n<tr><td>s(make1.1)                   </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              1</td><td style=\"text-align: right;\">         0</td></tr>\\n<tr><td>e(make1.1)|s(put1.1)|s(put.0)</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">         1</td></tr>\\n<tr><td>e(put.0)                     </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">         0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  make1.1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>make.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  make1.1</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\\n<tr><td>make.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\\n<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386557bc70aa4ec08f7a298028aa7c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                    </th><th style=\"text-align: right;\">  e(put1.1)</th><th style=\"text-align: right;\">  s(make.0)</th><th style=\"text-align: right;\">  e(make.0)</th><th style=\"text-align: right;\">  s(make1.1)</th><th style=\"text-align: right;\">  e(make1.1)|s(put1.1)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>e(put1.1)           </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\n",
       "<tr><td>s(make.0)           </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\n",
       "<tr><td>e(make.0)           </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\n",
       "<tr><td>s(make1.1)          </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td>e(make1.1)|s(put1.1)</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                    </th><th style=\"text-align: right;\">  e(put1.1)</th><th style=\"text-align: right;\">  s(make.0)</th><th style=\"text-align: right;\">  e(make.0)</th><th style=\"text-align: right;\">  s(make1.1)</th><th style=\"text-align: right;\">  e(make1.1)|s(put1.1)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>e(put1.1)           </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\\n<tr><td>s(make.0)           </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\\n<tr><td>e(make.0)           </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\\n<tr><td>s(make1.1)          </td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     1</td></tr>\\n<tr><td>e(make1.1)|s(put1.1)</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">           0</td><td style=\"text-align: right;\">                     0</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  put.0</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  serve.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        1</td></tr>\n",
       "<tr><td>put.0  </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        3</td></tr>\n",
       "<tr><td>make.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\n",
       "<tr><td>serve.0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">        1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>       </th><th style=\"text-align: right;\">  put1.1</th><th style=\"text-align: right;\">  put.0</th><th style=\"text-align: right;\">  make.0</th><th style=\"text-align: right;\">  make1.1</th><th style=\"text-align: right;\">  serve.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>put1.1 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        1</td></tr>\\n<tr><td>put.0  </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        3</td></tr>\\n<tr><td>make.0 </td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\\n<tr><td>make1.1</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">        0</td></tr>\\n<tr><td>serve.0</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">        2</td><td style=\"text-align: right;\">        1</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ccf27fa91949569408e65843c2609d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                                                             </th><th style=\"text-align: right;\">  e(make1.1)|s(put1.1)|e(make.0)|s(put.0)</th><th style=\"text-align: right;\">  e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>e(make1.1)|s(put1.1)|e(make.0)|s(put.0)                      </td><td style=\"text-align: right;\">                                        0</td><td style=\"text-align: right;\">                                                              1</td></tr>\n",
       "<tr><td>e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1)</td><td style=\"text-align: right;\">                                        1</td><td style=\"text-align: right;\">                                                              1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                                                             </th><th style=\"text-align: right;\">  e(make1.1)|s(put1.1)|e(make.0)|s(put.0)</th><th style=\"text-align: right;\">  e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>e(make1.1)|s(put1.1)|e(make.0)|s(put.0)                      </td><td style=\"text-align: right;\">                                        0</td><td style=\"text-align: right;\">                                                              1</td></tr>\\n<tr><td>e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1)</td><td style=\"text-align: right;\">                                        1</td><td style=\"text-align: right;\">                                                              1</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>      </th><th style=\"text-align: right;\">  move.0</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>move.0</td><td style=\"text-align: right;\">       7</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed6947a68f347e48e3582832396e471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                   </th><th style=\"text-align: right;\">  e(move.0)|s(move.0)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>e(move.0)|s(move.0)</td><td style=\"text-align: right;\">                    1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>                   </th><th style=\"text-align: right;\">  e(move.0)|s(move.0)</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>e(move.0)|s(move.0)</td><td style=\"text-align: right;\">                    1</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_machines_overall_list = []\n",
    "\n",
    "for index, ts_class in enumerate(transition_sets_per_class):\n",
    "    fsms_per_class = []\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    num_fsms = len(ts_class)\n",
    "    print(\"Number of FSMS:\" + str(num_fsms))\n",
    "    \n",
    "    for fsm_no, ts in enumerate(ts_class):\n",
    "        fsm_graph = nx.DiGraph()\n",
    "        \n",
    "        printmd(\"#### FSM \" + str(fsm_no))\n",
    "        for t in ts:\n",
    "            source = \"s(\" + str(t) + \")\"\n",
    "            target = \"e(\" + str(t) + \")\"\n",
    "            fsm_graph.add_edge(source,target,weight=t)\n",
    "        \n",
    "       \n",
    "        t_df = adjacency_matrix_list[index].loc[list(ts), list(ts)] #transition df for this fsm\n",
    "        print_table(t_df)\n",
    "        \n",
    "        \n",
    "        # merge end(t1) = start(t2) from transition df\n",
    "        \n",
    "        edge_t_list = [] # edge transition list\n",
    "        for i in range(t_df.shape[0]):\n",
    "            for j in range(t_df.shape[1]):\n",
    "                \n",
    "                if t_df.iloc[i, j] != 'hole':\n",
    "                    if t_df.iloc[i, j] > 0:\n",
    "                        for node in fsm_graph.nodes():\n",
    "                            if \"e(\"+t_df.index[i]+\")\" in node:\n",
    "                                merge_node1 = node\n",
    "                            if \"s(\"+t_df.index[j]+\")\" in node:\n",
    "                                merge_node2 = node\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "\n",
    "                        fsm_graph = nx.contracted_nodes(fsm_graph, merge_node1, merge_node2 , self_loops=True)\n",
    "\n",
    "                        if merge_node1 != merge_node2:\n",
    "                            mapping = {merge_node1: merge_node1 + \"|\" + merge_node2} \n",
    "                            fsm_graph = nx.relabel_nodes(fsm_graph, mapping)\n",
    "\n",
    "        # we need to complete the list of transitions \n",
    "        # that can happen on self-loop nodes \n",
    "        # as these have been overwritten (as graph is not MultiDiGraph)\n",
    "        \n",
    "        sl_state_list = list(nx.nodes_with_selfloops(fsm_graph)) # self looping states.\n",
    "        # if state is self-looping\n",
    "        t_list = []\n",
    "        if len(sl_state_list)>0: \n",
    "            # if s(T1) and e(T1) are there for same node, this T1 can self-loop occur.\n",
    "            for s in sl_state_list:\n",
    "                for sub_s in s.split('|'):\n",
    "                    if sub_s[0] == 'e':\n",
    "                        if ('s' + sub_s[1:]) in s.split('|'):\n",
    "                            t_list.append(sub_s[2:-1])\n",
    "                fsm_graph[s][s]['weight'] = '|'.join(t_list)\n",
    "        \n",
    "        \n",
    "\n",
    "               \n",
    "        plot_cytographs_fsm(fsm_graph,domain_name)\n",
    "        df = nx.to_pandas_adjacency(fsm_graph, nodelist=fsm_graph.nodes(), weight = 1)\n",
    "        print_table(df)\n",
    "        fsms_per_class.append(fsm_graph)\n",
    "    state_machines_overall_list.append(fsms_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## USER INPUT 3: Rename States. \n",
    "\n",
    "\n",
    "As states are shown in terms of end and start of transitions, user can rename them for easy readability later on.\n",
    "\n",
    "If states are renamed, certain hardcoded aspects of code won't work. It is advisable to create a  separate state dictionary and use it after step 9: (formation of PDDL model) to replace states in PDDL code.\n",
    "\n",
    "\n",
    "This also makes it easier to specify problem statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic creation: rename states as integers 0, 1, 2 .. etc. for each fsm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2380dd00cd4352bcf14cc350739d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a810d695af0948169bb05d027c367dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bc0e735bf540f0b36f42fb45c3cdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580f337247704735a5f14b0b7f625585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975ffaed64694023b1574bd8f17a53e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479a45e25e694394a016e0d5dcdb8c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1300a4699c8845c78f8cdaa15cc4a882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5bb25e4c5f41da90b6a607672ff629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ce6179f1a547ea94ea42fb6948b115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8897ba5dd9f7469494c22303a768aa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An Automatic state dictionary is added here where states are \n",
    "# renamed as 0, 1, 2 etc. for a specific FSM\n",
    "\n",
    "state_mappings_class = []\n",
    "state_machines_overall_list_2 = []\n",
    "for index, fsm_graphs in enumerate(state_machines_overall_list):\n",
    "    state_mappings_fsm = []\n",
    "    fsms_per_class_2 = []\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    num_fsms = len(fsm_graphs)\n",
    "    print(\"Number of FSMS:\" + str(num_fsms))\n",
    "    \n",
    "    for fsm_no, G in enumerate(fsm_graphs):\n",
    "        \n",
    "        state_mapping = {k: v for v, k in enumerate(G.nodes())}\n",
    "        G_copy = nx.relabel_nodes(G, state_mapping)\n",
    "        \n",
    "        plot_cytographs_fsm(G, domain_name)\n",
    "        plot_cytographs_fsm(G_copy, domain_name)\n",
    "        printmd(\"Fsm \"+ str(fsm_no))\n",
    "        fsms_per_class_2.append(G_copy)\n",
    "        state_mappings_fsm.append(state_mapping)\n",
    "        \n",
    "    state_machines_overall_list_2.append(fsms_per_class_2)\n",
    "    state_mappings_class.append(state_mappings_fsm)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the graph, User can specify states here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User can specify states here.\n",
    "# assign your states in state dictionary called state_mapping\n",
    "# e.g. state_mapping['e(removewheek.2)|s(putonwheel.2)'] = 'jack_free_to_use'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Induction of parameterized state machines\n",
    "Create and test hypothesis for state parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Form Hyp for HS (Hypothesis set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 0 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hypothesis created\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 0 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hypothesis created\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 1 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hypothesis created\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 2 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hypothesis created\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 0 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 hypothesis created\n"
     ]
    }
   ],
   "source": [
    "HS_list = []\n",
    "ct_list = []\n",
    "\n",
    "# for transition set of each class\n",
    "for index, ts_class in enumerate(transition_sets_per_class):\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    \n",
    "    ct_per_class = []\n",
    "    HS_per_class = []\n",
    "    \n",
    "    # for transition set of each fsm in a class\n",
    "    for fsm_no, ts in enumerate(ts_class):\n",
    "        printmd(\"#### FSM: \" + str(fsm_no) + \" Hypothesis Set\")\n",
    "        \n",
    "        # transition matrix for the ts\n",
    "        t_df = adjacency_matrix_list[index].loc[list(ts), list(ts)]\n",
    "        ct_in_fsm = set()  # find consecutive transition set for a state machine in a class.\n",
    "        for i in range(t_df.shape[0]):\n",
    "            for j in range(t_df.shape[1]):\n",
    "                if t_df.iloc[i, j] != 'hole':\n",
    "                    if t_df.iloc[i, j] > 0:\n",
    "                        ct_in_fsm.add((t_df.index[i], t_df.columns[j]))\n",
    "        \n",
    "        ct_per_class.append(ct_in_fsm)\n",
    "        \n",
    "        # add to hypothesis set\n",
    "        HS = set()\n",
    "        \n",
    "        # for each pair B.k and C.l in TS s.t. e(B.k) = S = s(C.l)\n",
    "        for ct in ct_in_fsm:\n",
    "            B = ct[0].split('.')[0] # action name of T1\n",
    "            k = int(ct[0].split('.')[1]) # argument index of T1\n",
    "            \n",
    "            C = ct[1].split('.')[0] # action name of T2\n",
    "            l = int(ct[1].split('.')[1]) # argument index of T2\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # When both actions B and C contain another argument of the same sort G' in position k' and l' respectively, \n",
    "            # we hypothesise that there may be a relation between sorts G and G'.\n",
    "            for seq in sequences:\n",
    "                for actarg_tuple in seq:\n",
    "                    arglist1 = []\n",
    "                    arglist2 = []\n",
    "                    if actarg_tuple[0] == B: #if action name is same as B\n",
    "                        arglist1 = actarg_tuple[1].copy()\n",
    "#                         arglist1.remove(actarg_tuple[1][k]) # remove k from arglist\n",
    "                        for actarg_tuple_prime in seq: #loop through seq again.\n",
    "                            if actarg_tuple_prime[0] == C:\n",
    "                                arglist2 = actarg_tuple_prime[1].copy()\n",
    "#                                 arglist2.remove(actarg_tuple_prime[1][l]) # remove l from arglist\n",
    "                                \n",
    "\n",
    "                        # for arg lists of actions B and C, if class is same add a hypothesis set.\n",
    "                        for i in range(len(arglist1)): # if len is 0, we don't go in\n",
    "                            for j in range(len(arglist2)):\n",
    "                                class1 = get_class_index(arglist1[i], classes)\n",
    "                                class2 = get_class_index(arglist2[j], classes)\n",
    "                                if class1 == class2: # if object at same position have same classes\n",
    "                                    # add hypothesis to hypothesis set.\n",
    "                                    if (k!=i) and (l!=j):\n",
    "                                        HS.add((frozenset({\"e(\"+B+\".\"+ str(k)+\")\", \"s(\"+C+\".\"+str(l)+\")\"}),B,k,i,C,l,j,class_names[index],class_names[class1]))\n",
    "        print(str(len(HS))+ \" hypothesis created\")\n",
    "#         for h in HS:\n",
    "#             print(h)\n",
    "        \n",
    "        HS_per_class.append(HS)\n",
    "    HS_list.append(HS_per_class)\n",
    "    ct_list.append(ct_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test hyp against E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 0 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hypothesis retained\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 0 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hypothesis retained\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 1 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hypothesis retained\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 2 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hypothesis retained\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### FSM: 0 Hypothesis Set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 hypothesis retained\n"
     ]
    }
   ],
   "source": [
    "HS_list_retained = []\n",
    "for index, HS_class in enumerate(HS_list):\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    HS_per_class_retained = []\n",
    "\n",
    "\n",
    "    for fsm_no, HS in enumerate(HS_class):\n",
    "        printmd(\"#### FSM: \" + str(fsm_no) + \" Hypothesis Set\")\n",
    "\n",
    "        count=0\n",
    "        HS_copy = HS.copy()\n",
    "        HS_copy2 = HS.copy()\n",
    "\n",
    "        \n",
    "        # for each object O occuring in Ou\n",
    "        for O in arguments:\n",
    "            #   for each pair of transitions Ap.m and Aq.n consecutive for O in seq\n",
    "            ct = []\n",
    "            for seq in sequences:\n",
    "                for actarg_tuple in seq:\n",
    "                    act = actarg_tuple[0]\n",
    "                    for j, arg in enumerate(actarg_tuple[1]):\n",
    "                        if arg == O:\n",
    "                            ct.append((act + '.' + str(j), actarg_tuple[1]))\n",
    "\n",
    "\n",
    "            for i in range(len(ct)-1):\n",
    "                A_p = ct[i][0].split('.')[0]\n",
    "                m = int(ct[i][0].split('.')[1])\n",
    "                A_q = ct[i+1][0].split('.')[0]\n",
    "                n = int(ct[i+1][0].split('.')[1]) \n",
    "\n",
    "                # for each hypothesis H s.t. A_p = B, m = k, A_q = C, n = l\n",
    "\n",
    "                for H in HS_copy2:\n",
    "                    if A_p == H[1] and m == H[2] and A_q == H[4] and n == H[5]:\n",
    "                        k_prime = H[3]\n",
    "                        l_prime = H[6]\n",
    "\n",
    "                        # if O_p,k_prime = Q_q,l_prime\n",
    "                        if ct[i][1][k_prime] != ct[i+1][1][l_prime]:\n",
    "                            if H in HS_copy:\n",
    "                                HS_copy.remove(H)\n",
    "                                count += 1\n",
    "\n",
    "        print(str(len(HS_copy))+ \" hypothesis retained\")\n",
    "        # state machine\n",
    "#         if len(HS_copy)>0:\n",
    "#             plot_cytographs_fsm(state_machines_overall_list[index][fsm_no],domain_name)\n",
    "#         for H in HS_copy:\n",
    "#             print(H)\n",
    "        HS_per_class_retained.append(HS_copy)\n",
    "    HS_list_retained.append(HS_per_class_retained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Creation and merging of state parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: creating and merging state params\n",
      "[['v0', 'v1', 'v2']]\n",
      "gluten-free\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "No. of params earlier:3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "No. of params after merging:1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "sandwich\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "No. of params earlier:1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "No. of params after merging:1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "sandwich\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "No. of params earlier:1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "No. of params after merging:1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "sandwich\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "No. of params earlier:1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "No. of params after merging:1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "kitchen\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "No. of params earlier:0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "No. of params after merging:0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Each hypothesis refers to an incoming and outgoing transition \n",
    "# through a particular state of an FSM\n",
    "# and matching associated transitions can be considered\n",
    "# to set and read parameters of a state.\n",
    "# Since there maybe multiple transitions through a give state,\n",
    "# it is possible for the same parameter to have multiple\n",
    "# pairwise occurences.\n",
    "\n",
    "print(\"Step 6: creating and merging state params\")\n",
    "param_bindings_list_overall = []\n",
    "for classindex, HS_per_class in enumerate(HS_list_retained):\n",
    "    param_bind_per_class = []\n",
    "    \n",
    "    \n",
    "    for fsm_no, HS_per_fsm in enumerate(HS_per_class):\n",
    "        param_binding_list = []\n",
    "        \n",
    "        # fsm in consideration\n",
    "        G = state_machines_overall_list[classindex][fsm_no]\n",
    "        state_list = G.nodes()\n",
    "        \n",
    "        # creation\n",
    "        for index,h in enumerate(HS_per_fsm):\n",
    "            param_binding_list.append((h,\"v\"+str(index)))\n",
    "        \n",
    "        merge_pl = [] # parameter to merge list\n",
    "        if len(param_binding_list)>1:\n",
    "            # merging\n",
    "            pairs = findsubsets(param_binding_list, 2)\n",
    "            for pair in pairs:\n",
    "                h_1 = pair[0][0]\n",
    "                h_2 = pair[1][0]\n",
    "                \n",
    "                \n",
    "                # equate states\n",
    "                state_eq_flag = False\n",
    "                for s_index, state in enumerate(state_list):\n",
    "                    # if both hyp states appear in single state in fsm\n",
    "                    if list(h_1[0])[0] in state:\n",
    "                        if list(h_1[0])[0] in state:\n",
    "                            state_eq_flag =True\n",
    "                            \n",
    "                \n",
    "                if ((state_eq_flag and h_1[1] == h_2[1] and h_1[2] == h_2[2] and h_1[3] == h_2[3]) or (state_eq_flag and h_1[4] == h_2[4] and h_1[5] == h_2[5] and h_1[6] == h_2[6])):\n",
    "                    merge_pl.append(list([pair[0][1], pair[1][1]]))\n",
    "          \n",
    "        \n",
    "       \n",
    "        #inner lists to sets (to list of sets)\n",
    "        l=[set(x) for x in merge_pl]\n",
    "\n",
    "        #cartesian product merging elements if some element in common\n",
    "        for a,b in itertools.product(l,l):\n",
    "            if a.intersection( b ):\n",
    "                a.update(b)\n",
    "                b.update(a)\n",
    "\n",
    "        #back to list of lists\n",
    "        l = sorted( [sorted(list(x)) for x in l])\n",
    "\n",
    "        #remove dups\n",
    "        merge_pl = list(l for l,_ in itertools.groupby(l))\n",
    "        \n",
    "        # sort\n",
    "        for pos, l in enumerate(merge_pl):\n",
    "            merge_pl[pos] = sorted(l, key = lambda x: int(x[1:]))\n",
    "        \n",
    "        print(merge_pl) # equal params appear in a list in this list.\n",
    "          \n",
    "            \n",
    "        for z,pb in enumerate(param_binding_list):\n",
    "            for l in merge_pl:\n",
    "                if pb[1] in l:\n",
    "                    # update pb\n",
    "                    param_binding_list[z] = (param_binding_list[z][0], l[0])\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "        param_bind_per_class.append(param_binding_list)\n",
    "        print(class_names[classindex])\n",
    "        \n",
    "        # set of params per class\n",
    "        param = set()\n",
    "        for pb in param_binding_list:\n",
    "#             print(pb)\n",
    "            param.add(pb[1])\n",
    "            \n",
    "        # num of params per class\n",
    "        printmd(\"No. of params earlier:\" + str(len(param_binding_list)))\n",
    "        printmd(\"No. of params after merging:\" + str(len(param)))\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    param_bindings_list_overall.append(param_bind_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Remove Parameter Flaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluten-free\n",
      "3/3 param retained\n",
      "((frozenset({'s(put1.0)', 'e(make1.0)'}), 'make1', 0, 1, 'put1', 0, 1, 'gluten-free', 'sandwich'), 'v0')\n",
      "((frozenset({'e(put1.0)', 's(make1.0)'}), 'put1', 0, 1, 'make1', 0, 1, 'gluten-free', 'sandwich'), 'v0')\n",
      "((frozenset({'s(make1.0)', 'e(make1.0)'}), 'make1', 0, 1, 'make1', 0, 1, 'gluten-free', 'sandwich'), 'v0')\n",
      "sandwich\n",
      "1/1 param retained\n",
      "((frozenset({'s(put1.1)', 'e(make1.1)'}), 'make1', 1, 0, 'put1', 1, 0, 'sandwich', 'gluten-free'), 'v0')\n",
      "1/1 param retained\n",
      "((frozenset({'s(put1.1)', 'e(make1.1)'}), 'make1', 1, 0, 'put1', 1, 0, 'sandwich', 'gluten-free'), 'v0')\n",
      "1/1 param retained\n",
      "((frozenset({'s(put1.1)', 'e(make1.1)'}), 'make1', 1, 0, 'put1', 1, 0, 'sandwich', 'gluten-free'), 'v0')\n",
      "kitchen\n",
      "0/0 param retained\n"
     ]
    }
   ],
   "source": [
    "# Removing State Params.\n",
    "# Flaw occurs Object can reach state S with param P having an inderminate value.\n",
    "# There is transition s.t. end(B.k) = S. \n",
    "# but there is no h = <S,B,k,k',C,l,l',G,G') and <h,P> is in bindings.\n",
    "\n",
    "para_bind_overall_fault_removed  = []\n",
    "for classindex, fsm_per_class in enumerate(state_machines_overall_list):\n",
    "    print(class_names[classindex])\n",
    "    pb_per_class_fault_removed = []\n",
    "\n",
    "    for fsm_no, G in enumerate(fsm_per_class):\n",
    "        \n",
    "        pb_per_fsm_fault_removed = []\n",
    "        # G is fsm in consideration\n",
    "        faulty_pb = []\n",
    "        for state in G.nodes():\n",
    "            inedges = G.in_edges(state, data=True)\n",
    "            \n",
    "            for ie in inedges:\n",
    "                tr = ie[2]['weight']\n",
    "                t_list = tr.split('|')\n",
    "                for t in t_list:\n",
    "                    B = t.split('.')[0]\n",
    "                    k = t.split('.')[1]\n",
    "                    S = 'e(' + t + ')'\n",
    "                    flaw = True\n",
    "                    for pb in param_bindings_list_overall[classindex][fsm_no]:\n",
    "                        H = pb[0]\n",
    "                        v = pb[1]\n",
    "                        if (S in set(H[0])) and (B==H[1]) and (int(k)==H[2]) :\n",
    "                            # this pb is okay\n",
    "                            flaw=False\n",
    "#                     print(flaw)\n",
    "                    if flaw:\n",
    "                        for pb in param_bindings_list_overall[classindex][fsm_no]:\n",
    "                            H = pb[0]\n",
    "                            H_states = list(H[0])\n",
    "                            for h_state in H_states:\n",
    "                                if h_state in state:\n",
    "                                    if pb not in faulty_pb:\n",
    "                                        faulty_pb.append(pb) # no duplicates\n",
    "        \n",
    "        for pb in param_bindings_list_overall[classindex][fsm_no]:\n",
    "            if pb not in faulty_pb:\n",
    "                pb_per_fsm_fault_removed.append(pb)\n",
    "        \n",
    "                                \n",
    "                        \n",
    "                        \n",
    "        print(str(len(pb_per_fsm_fault_removed)) + \"/\" + str(len(param_bindings_list_overall[classindex][fsm_no])) + \" param retained\")\n",
    "        for pb in pb_per_fsm_fault_removed:\n",
    "            print(pb)\n",
    "\n",
    "                \n",
    "        \n",
    "        pb_per_class_fault_removed.append(pb_per_fsm_fault_removed)\n",
    "    para_bind_overall_fault_removed.append(pb_per_class_fault_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: (TODO) Static Preconditions via LOP\n",
    "As further enhancement, one can add step 8: Extraction of static preconditions from the LOCM paper.\n",
    "However, LOP algorithm is better version of that step.\n",
    "\n",
    "Insert [LOP](https://www.aaai.org/ocs/index.php/ICAPS/ICAPS15/paper/viewFile/10621/10401) here for finding static preconditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9:  Formation of PDDL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;********************Learned PDDL domain******************\n",
      "(define  (domain childsnack_domain)\n",
      "  (:requirements :typing)\n",
      "  (:types gluten-free sandwich kitchen)\n",
      "  (:predicates\n",
      "    (gluten-free_fsm0_e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0) ?v0 - sandwich)\n",
      "    (sandwich_fsm0_e(put1.1))\n",
      "    (sandwich_fsm0_s(make1.1))\n",
      "    (sandwich_fsm0_e(make1.1)|s(put1.1)|s(put.0) ?v0 - gluten-free)\n",
      "    (sandwich_fsm0_e(put.0))\n",
      "    (sandwich_fsm1_e(put1.1))\n",
      "    (sandwich_fsm1_s(make.0))\n",
      "    (sandwich_fsm1_e(make.0))\n",
      "    (sandwich_fsm1_s(make1.1))\n",
      "    (sandwich_fsm1_e(make1.1)|s(put1.1) ?v0 - gluten-free)\n",
      "    (sandwich_fsm2_e(make1.1)|s(put1.1)|e(make.0)|s(put.0) ?v0 - gluten-free)\n",
      "    (sandwich_fsm2_e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1))\n",
      "    (kitchen_fsm0_e(move.0)|s(move.0))\n",
      "  )\n",
      "\n",
      "  (:action  make   :parameters  (?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (sandwich_fsm1_s(make.0))\n",
      "   )\n",
      "   :effect   (and\n",
      "        (sandwich_fsm1_e(make.0))\n",
      "  ))\n",
      "\n",
      "  (:action  put   :parameters  (?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (sandwich_fsm0_e(make1.1)|s(put1.1)|s(put.0) ?v0 - gluten-free)\n",
      "        (sandwich_fsm2_e(make1.1)|s(put1.1)|e(make.0)|s(put.0) ?v0 - gluten-free)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (sandwich_fsm0_e(put.0))\n",
      "        (sandwich_fsm2_e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1))\n",
      "  ))\n",
      "\n",
      "  (:action  move   :parameters  (?tray - kitchen )\n",
      "   :precondition   (and\n",
      "        (kitchen_fsm0_e(move.0)|s(move.0))\n",
      "   )\n",
      "   :effect   (and\n",
      "        (kitchen_fsm0_e(move.0)|s(move.0))\n",
      "  ))\n",
      "\n",
      "  (:action  put1   :parameters  (?gluten-free - gluten-free ?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (gluten-free_fsm0_e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0) ?v0 - sandwich)\n",
      "        (sandwich_fsm0_e(make1.1)|s(put1.1)|s(put.0) ?v0 - gluten-free)\n",
      "        (sandwich_fsm1_e(make1.1)|s(put1.1) ?v0 - gluten-free)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (gluten-free_fsm0_e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0) ?v0 - sandwich)\n",
      "        (sandwich_fsm0_e(put1.1))\n",
      "        (sandwich_fsm1_e(put1.1))\n",
      "  ))\n",
      "\n",
      "  (:action  make1   :parameters  (?gluten-free - gluten-free ?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (gluten-free_fsm0_e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0) ?v0 - sandwich)\n",
      "        (sandwich_fsm0_s(make1.1))\n",
      "        (sandwich_fsm1_s(make1.1))\n",
      "        (sandwich_fsm2_e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1))\n",
      "   )\n",
      "   :effect   (and\n",
      "        (gluten-free_fsm0_e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0) ?v0 - sandwich)\n",
      "        (sandwich_fsm0_e(make1.1)|s(put1.1)|s(put.0) ?v0 - gluten-free)\n",
      "        (sandwich_fsm1_e(make1.1)|s(put1.1) ?v0 - gluten-free)\n",
      "        (sandwich_fsm2_e(make1.1)|s(put1.1)|e(make.0)|s(put.0) ?v0 - gluten-free)\n",
      "  ))\n",
      "\n",
      "  (:action  serve   :parameters  (?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (sandwich_fsm2_e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1))\n",
      "   )\n",
      "   :effect   (and\n",
      "        (sandwich_fsm2_e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1))\n",
      "  ))\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get action schema\n",
    "print(\";;********************Learned PDDL domain******************\")\n",
    "output_file = \"output/\"+ domain_name + \"/\" +  domain_name + \".pddl\"\n",
    "write_file = open(output_file, 'w')\n",
    "write_line = \"(define\"\n",
    "write_line += \"  (domain \"+ domain_name+\")\\n\"\n",
    "write_line += \"  (:requirements :typing)\\n\"\n",
    "write_line += \"  (:types\"\n",
    "for class_name in class_names:\n",
    "    write_line += \" \" + class_name\n",
    "write_line += \")\\n\"\n",
    "write_line += \"  (:predicates\\n\"\n",
    "\n",
    "# one predicate to represent each object state\n",
    "\n",
    "predicates = []\n",
    "for class_index, pb_per_class in enumerate(para_bind_overall_fault_removed):\n",
    "    for fsm_no, pbs_per_fsm in enumerate(pb_per_class):\n",
    "        for state_index, state in enumerate(state_machines_overall_list[class_index][fsm_no].nodes()):\n",
    "            \n",
    "            state_set = set(state.split('|'))\n",
    "            predicate = \"\"\n",
    "       \n",
    "            write_line += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_\" +  state\n",
    "            predicate += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_\" + state\n",
    "            for pb in pbs_per_fsm:\n",
    "                    if set(pb[0][0]) <= state_set:\n",
    "                        if \" ?\"+pb[1] + \" - \" + str(pb[0][8]) not in predicate:\n",
    "                            write_line += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "                            predicate += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "    \n",
    "            write_line += \")\\n\"\n",
    "            predicate += \")\"\n",
    "            predicates.append(predicate)\n",
    "write_line += \"  )\\n\"\n",
    "            \n",
    "for action_index, action in enumerate(actions):\n",
    "    write_line += \"\\n\"\n",
    "    write_line += \"  (:action\"\n",
    "    write_line += \"  \" + action + \" \"\n",
    "    write_line += \"  :parameters\"\n",
    "    write_line += \"  (\"\n",
    "    arg_already_written_flag = False\n",
    "    params_per_action = []\n",
    "    args_per_action = []\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            if not arg_already_written_flag:\n",
    "                if actarg_tuple[0] == action:\n",
    "                    arglist = []\n",
    "                    for arg in actarg_tuple[1]:\n",
    "                        write_line += \"?\"+arg + \" - \" + class_names[get_class_index(arg,classes)] + \" \"\n",
    "                        arglist.append(arg)\n",
    "                    args_per_action.append(arglist)\n",
    "                    params_per_action.append(actarg_tuple[1])\n",
    "                    arg_already_written_flag = True\n",
    "    write_line += \")\\n\"\n",
    "\n",
    "\n",
    "    # need to use FSMS to get preconditions and effects.\n",
    "    # Start-state = precondition. End state= Effect\n",
    "    preconditions = []\n",
    "    effects = []\n",
    "    for arglist in params_per_action:\n",
    "        for arg in arglist:\n",
    "            current_class_index = get_class_index(arg, classes)\n",
    "            for fsm_no, G in enumerate(state_machines_overall_list[current_class_index]):\n",
    "#                \n",
    "                for start, end, weight in G.edges(data='weight'):\n",
    "                    _actions = weight.split('|')\n",
    "                    for _action in _actions:\n",
    "                        \n",
    "                        if _action.split('.')[0] == action:\n",
    "                            for predicate in predicates:\n",
    "                                pred = predicate.split()[0].lstrip(\"(\")\n",
    "                                clss = pred.split('_')[0]\n",
    "                                fsm = pred.split('_')[1]\n",
    "                                state = set(pred.split('_')[2].replace('))',')').split('|'))\n",
    "\n",
    "\n",
    "\n",
    "                                if clss == class_names[current_class_index]:\n",
    "                                    if fsm == \"fsm\" + str(fsm_no):\n",
    "\n",
    "                                        if state == set(start.split('|')):\n",
    "\n",
    "                                            if predicate not in preconditions:\n",
    "                                                preconditions.append(predicate)\n",
    "\n",
    "                                        if state == set(end.split('|')):\n",
    "                                            if predicate not in effects:\n",
    "                                                effects.append(predicate)\n",
    "                            break\n",
    "                                        \n",
    "    \n",
    "                \n",
    "\n",
    "    write_line += \"   :precondition\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for precondition in preconditions:\n",
    "        # precondition = precondition.replace(?)\n",
    "        write_line += \"    \"+precondition+\"\\n\"\n",
    "    write_line += \"   )\\n\"\n",
    "    write_line += \"   :effect\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for effect in effects:\n",
    "        write_line += \"    \" + effect + \"\\n\"\n",
    "    write_line += \"  )\"\n",
    "\n",
    "    write_line += \")\\n\"\n",
    "\n",
    "write_line += \")\\n\" #domain ending bracket\n",
    "\n",
    "\n",
    "print(write_line)\n",
    "\n",
    "write_file.write(write_line)\n",
    "write_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating PDDL -- Fixing Syntax by replacing predicates with state dictionary values\n",
    "This is required because PDDL syntax doesn't support extra paranthesis () which occur in states (transitions occuring in states as 'start(t1)' or  'end(t1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;********************Learned PDDL domain******************\n",
      "(define  (domain childsnack_domain)\n",
      "  (:requirements :typing)\n",
      "  (:types gluten-free sandwich kitchen)\n",
      "  (:predicates\n",
      "    (gluten-free_fsm0_state0 ?v0 - sandwich)\n",
      "    (sandwich_fsm0_state0)\n",
      "    (sandwich_fsm0_state1)\n",
      "    (sandwich_fsm0_state2 ?v0 - gluten-free)\n",
      "    (sandwich_fsm0_state3)\n",
      "    (sandwich_fsm1_state0)\n",
      "    (sandwich_fsm1_state1)\n",
      "    (sandwich_fsm1_state2)\n",
      "    (sandwich_fsm1_state3)\n",
      "    (sandwich_fsm1_state4 ?v0 - gluten-free)\n",
      "    (sandwich_fsm2_state0 ?v0 - gluten-free)\n",
      "    (sandwich_fsm2_state1)\n",
      "    (kitchen_fsm0_state0)\n",
      "  )\n",
      "  (:action  make   :parameters  (?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (sandwich_fsm1_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (sandwich_fsm1_state2)\n",
      "  ))\n",
      "\n",
      "  (:action  put   :parameters  (?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (sandwich_fsm0_state2 ?v0 - gluten-free)\n",
      "        (sandwich_fsm2_state0 ?v0 - gluten-free)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (sandwich_fsm0_state3)\n",
      "        (sandwich_fsm2_state1)\n",
      "  ))\n",
      "\n",
      "  (:action  move   :parameters  (?tray - kitchen )\n",
      "   :precondition   (and\n",
      "        (kitchen_fsm0_state0)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (kitchen_fsm0_state0)\n",
      "  ))\n",
      "\n",
      "  (:action  put1   :parameters  (?gluten-free - gluten-free ?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (gluten-free_fsm0_state0 ?v0 - sandwich)\n",
      "        (sandwich_fsm0_state2 ?v0 - gluten-free)\n",
      "        (sandwich_fsm1_state4 ?v0 - gluten-free)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (gluten-free_fsm0_state0 ?v0 - sandwich)\n",
      "        (sandwich_fsm0_state0)\n",
      "        (sandwich_fsm1_state0)\n",
      "  ))\n",
      "\n",
      "  (:action  make1   :parameters  (?gluten-free - gluten-free ?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (gluten-free_fsm0_state0 ?v0 - sandwich)\n",
      "        (sandwich_fsm0_state1)\n",
      "        (sandwich_fsm1_state3)\n",
      "        (sandwich_fsm2_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (gluten-free_fsm0_state0 ?v0 - sandwich)\n",
      "        (sandwich_fsm0_state2 ?v0 - gluten-free)\n",
      "        (sandwich_fsm1_state4 ?v0 - gluten-free)\n",
      "        (sandwich_fsm2_state0 ?v0 - gluten-free)\n",
      "  ))\n",
      "\n",
      "  (:action  serve   :parameters  (?sandwich - sandwich )\n",
      "   :precondition   (and\n",
      "        (sandwich_fsm2_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (sandwich_fsm2_state1)\n",
      "  ))\n",
      "\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get action schema\n",
    "print(\";;********************Learned PDDL domain******************\")\n",
    "output_file = \"output/\"+ domain_name + \"/\" +  domain_name + \".pddl\"\n",
    "write_file = open(output_file, 'w')\n",
    "write_line = \"(define\"\n",
    "write_line += \"  (domain \"+ domain_name+\")\\n\"\n",
    "write_line += \"  (:requirements :typing)\\n\"\n",
    "write_line += \"  (:types\"\n",
    "for class_name in class_names:\n",
    "    write_line += \" \" + class_name\n",
    "write_line += \")\\n\"\n",
    "write_line += \"  (:predicates\\n\"\n",
    "\n",
    "# one predicate to represent each object state\n",
    "\n",
    "predicates = []\n",
    "for class_index, pb_per_class in enumerate(para_bind_overall_fault_removed):\n",
    "    for fsm_no, pbs_per_fsm in enumerate(pb_per_class):\n",
    "        state_mapping = state_mappings_class[class_index][fsm_no]\n",
    "        \n",
    "        for state_index, state in enumerate(state_machines_overall_list[class_index][fsm_no].nodes()):\n",
    "            \n",
    "            state_set = set(state.split('|'))\n",
    "            predicate = \"\"\n",
    "       \n",
    "            write_line += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_state\" +  str(state_mapping[state])\n",
    "            predicate += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_state\" + str(state_mapping[state])\n",
    "            for pb in pbs_per_fsm:\n",
    "                    if set(pb[0][0]) <= state_set:\n",
    "                        if \" ?\"+pb[1] + \" - \" + str(pb[0][8]) not in predicate:\n",
    "                            write_line += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "                            predicate += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "    \n",
    "            write_line += \")\\n\"\n",
    "            predicate += \")\"\n",
    "            predicates.append(predicate)\n",
    "write_line += \"  )\\n\"\n",
    "            \n",
    "for action_index, action in enumerate(actions):\n",
    "    write_line += \"  (:action\"\n",
    "    write_line += \"  \" + action + \" \"\n",
    "    write_line += \"  :parameters\"\n",
    "    write_line += \"  (\"\n",
    "    arg_already_written_flag = False\n",
    "    params_per_action = []\n",
    "    args_per_action = []\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            if not arg_already_written_flag:\n",
    "                if actarg_tuple[0] == action:\n",
    "                    arglist = []\n",
    "                    for arg in actarg_tuple[1]:\n",
    "                        write_line += \"?\"+arg + \" - \" + class_names[get_class_index(arg,classes)] + \" \"\n",
    "                        arglist.append(arg)\n",
    "                    args_per_action.append(arglist)\n",
    "                    params_per_action.append(actarg_tuple[1])\n",
    "                    arg_already_written_flag = True\n",
    "    write_line += \")\\n\"\n",
    "\n",
    "\n",
    "    # need to use FSMS to get preconditions and effects.\n",
    "    # Start-state = precondition. End state= Effect\n",
    "    preconditions = []\n",
    "    effects = []\n",
    "    for arglist in params_per_action:\n",
    "        for arg in arglist:\n",
    "            current_class_index = get_class_index(arg, classes)\n",
    "            for fsm_no, G in enumerate(state_machines_overall_list[current_class_index]):\n",
    "                G_int = state_machines_overall_list_2[current_class_index][fsm_no]\n",
    "                state_mapping = state_mappings_class[current_class_index][fsm_no]\n",
    "                for start, end, weight in G_int.edges(data='weight'):\n",
    "                    _actions = weight.split('|')\n",
    "                    for _action in _actions:\n",
    "                        if _action.split('.')[0] == action:\n",
    "                            for predicate in predicates:\n",
    "                                pred = predicate.split()[0].lstrip(\"(\")\n",
    "                                clss = pred.split('_')[0]\n",
    "                                fsm = pred.split('_')[1]\n",
    "                                state_ind = pred.split('_')[2].rstrip(\")\")[-1]\n",
    "\n",
    "                                if clss == class_names[current_class_index]:\n",
    "                                    if fsm == \"fsm\" + str(fsm_no):\n",
    "                                        if int(state_ind) == int(start):\n",
    "                                            if predicate not in preconditions:\n",
    "                                                preconditions.append(predicate)\n",
    "                                                \n",
    "                                        if int(state_ind) == int(end):\n",
    "                                            if predicate not in effects:\n",
    "                                                effects.append(predicate)\n",
    "                            break\n",
    "                            \n",
    "\n",
    "                \n",
    "\n",
    "    write_line += \"   :precondition\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for precondition in preconditions:\n",
    "        write_line += \"    \"+precondition+\"\\n\"\n",
    "    write_line += \"   )\\n\"\n",
    "    write_line += \"   :effect\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for effect in effects:\n",
    "        write_line += \"    \" + effect + \"\\n\"\n",
    "    write_line += \"  )\"\n",
    "\n",
    "    write_line += \")\\n\\n\"\n",
    "\n",
    "write_line += \")\\n\" #domain ending bracket\n",
    "\n",
    "\n",
    "print(write_line)\n",
    "\n",
    "write_file.write(write_line)\n",
    "write_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Mapping: What are these states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Class 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea50ea93b374338b07945e1faf31a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c0da63bfd1472daf592f30d26de7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Class 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7b8ed8c56741889113e699fb5cc1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c062848d3a2446d392e02e5beaaae990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4def910ac25a46c48daacfc72f674d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded8098f6707484898f0c60d905e53eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b518e2ddde46dcb72d121a6f19b3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d564b39303824fee8e453e0c284ef7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Class 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FSMS:1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28009415b9a847e88cfecbfcc5875108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f32782fa0b84cbca3f1d308f0f72715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 400, 'height': 500, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To see what these states are, look at the following graphs\n",
    "\n",
    "for index, fsm_graphs in enumerate(state_machines_overall_list):\n",
    "    printmd(\"## Class \" + str(index))\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    print(\"Number of FSMS:\" + str(num_fsms))\n",
    "    \n",
    "    for fsm_no, G in enumerate(fsm_graphs):  \n",
    "        printmd(\"Fsm \"+ str(fsm_no))\n",
    "        plot_cytographs_fsm(state_machines_overall_list_2[index][fsm_no], domain_name)\n",
    "        plot_cytographs_fsm(G, domain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Mappings: Text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Class 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### gluten-free"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e(make1.0)|s(put1.0)|e(put1.0)|s(make1.0)': 0}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Class 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### sandwich"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e(make1.1)|s(put1.1)|s(put.0)': 2,\n",
      " 'e(put.0)': 3,\n",
      " 'e(put1.1)': 0,\n",
      " 's(make1.1)': 1}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e(make.0)': 2,\n",
      " 'e(make1.1)|s(put1.1)': 4,\n",
      " 'e(put1.1)': 0,\n",
      " 's(make.0)': 1,\n",
      " 's(make1.1)': 3}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e(make1.1)|s(put1.1)|e(make.0)|s(put.0)': 0,\n",
      " 'e(serve.0)|e(put.0)|s(make.0)|e(put1.1)|s(serve.0)|s(make1.1)': 1}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Class 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### kitchen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fsm 0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e(move.0)|s(move.0)': 0}\n"
     ]
    }
   ],
   "source": [
    "for index, sm_fsm in enumerate(state_mappings_class):\n",
    "    printmd(\"## Class \" + str(index))\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "\n",
    "    \n",
    "    for fsm_no, mapping in enumerate(sm_fsm):\n",
    "        printmd(\"Fsm \"+ str(fsm_no))\n",
    "        pprint(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding entities using spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(coref_resolved_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Jeff, Barbara and Nirmal are allergic to gluten. Shivam, and Kanav are non-allergic children.</br>Make a gluten-free sandwich with gluten-free cheese and corn bread.</br>Put gluten-free sandwich on a tray.</br>Move the tray from the kitchen to the table-5.</br>Serve gluten-free sandwich to Jeff.</br>Move the tray from the kitchen back from the table-5 to the kitchen.</br>Make a sandwich with cheese and wheat bread</br>Put sandwich on a tray.</br>Move the tray from the kitchen from kitchen to the table-11</br>Serve gluten-free sandwich to Shivam.</br>Move the tray from the kitchen back from table-11 to the kitchen.</br>Make a gluten-free sandwich with gluten-free cheese and corn bread.</br>Put gluten-free sandwich on a tray.</br>Move the tray from the kitchen the kitchen to the table-5.</br>Serve gluten-free sandwich to Jeff.</br>Move the tray from the kitchen back from the table-5 to the kitchen.</br>Make a gluten-free sandwich with gluten-free cheese and corn bread.</br>Put gluten-free sandwich on a tray.</br>Make a sandwich with cheese and wheat bread</br>Put sandwich on tray-7.</br>Move the tray from the kitchen the kitchen to the table-5.</br>Serve gluten-free sandwich to Nirmal.</br>Move the tray from the kitchen back from the table-5 to the kitchen.</br>Move tray-7 from kitchen to the table-11</br>Serve gluten-free sandwich to Kanav.\n",
       "Move tray-7 back from table-11 to the kitchen.\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(doc)), jupyter=True, style='ent', options = {'ents':['QUANTITY', 'TIME', 'LOC', 'DATE']})"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.4.2"
   }
  },
  "kernelspec": {
   "display_name": ".contextual_drl",
   "language": "python",
   "name": ".contextual_drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
